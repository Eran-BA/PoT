{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XklrO5R1A-Rl"
      },
      "source": [
        "# ðŸ§© Maze Scaling Benchmark - Proper Generation\n",
        "\n",
        "**Using Research-Grade Maze Generation (maze-dataset library)**\n",
        "\n",
        "This notebook uses the [maze-dataset](https://github.com/understanding-search/maze-dataset) library for high-quality maze generation with controllable difficulty.\n",
        "\n",
        "## âœ¨ Key Improvements:\n",
        "- âœ… **Proper algorithms**: DFS, Wilson's, Prim's (we use DFS for challenging mazes)\n",
        "- âœ… **Path length filtering**: Control difficulty by minimum solution length\n",
        "- âœ… **Guaranteed solvable**: No unsolvable mazes\n",
        "- âœ… **Long planning horizons**: Force 80+ step solutions for differentiation\n",
        "\n",
        "## Models Compared:\n",
        "- **Baseline**: Standard Transformer encoder-decoder\n",
        "- **PoH-HRM**: Pointer-over-Heads with Hierarchical Reasoning Module\n",
        "\n",
        "## Why Proper Generation Matters:\n",
        "**Old approach** (random walls): Path length ~16-20 â†’ All models get 100% âŒ  \n",
        "**New approach** (DFS + filtering): Path length 80+ â†’ Clear differentiation âœ…\n",
        "\n",
        "## Recommended Starting Point:\n",
        "- **Maze Size**: 20Ã—20 (large enough to be challenging)\n",
        "- **Min Path Length**: 80 (20% of grid size)\n",
        "- **Training**: 300-500 mazes\n",
        "- **Goal**: Test if HRM provides advantage on long-horizon planning\n",
        "\n",
        "---\n",
        "\n",
        "**Hardware**: Optimized for A100 GPU\n",
        "\n",
        "**Recent Architecture Fixes (Nov 2025):**\n",
        "- Fixed head routing to apply to per-head outputs BEFORE projection\n",
        "- Fixed positional encoding to only apply once (not R times)\n",
        "- Made HRM H-update gradients configurable (now differentiable by default)\n",
        "- Added configurable `grad_mode` for memory vs deep supervision tradeoff\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3hvcMiNA-Rl"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaSP4RrwA-Rm",
        "outputId": "3ef3dea5-6623-4f9e-ba38-22ebe1957530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'PoT'...\n",
            "remote: Enumerating objects: 1110, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 1110 (delta 48), reused 51 (delta 25), pack-reused 1035 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1110/1110), 822.42 KiB | 25.70 MiB/s, done.\n",
            "Resolving deltas: 100% (589/589), done.\n",
            "/content/PoT\n"
          ]
        }
      ],
      "source": [
        "# Clone repository and ensure latest fixes\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n",
        "!git pull origin main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEE3xhpCA-Rm"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets scipy numpy tqdm matplotlib seaborn\n",
        "\n",
        "# Install maze-dataset library for proper maze generation\n",
        "!pip install maze-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpvA2l8wA-Rm",
        "outputId": "13e8dacd-b497-40f1-9ec1-231661f050bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Available: True\n",
            "GPU Name: NVIDIA A100-SXM4-80GB\n",
            "GPU Memory: 85.17 GB\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
        "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\" if torch.cuda.is_available() else \"N/A\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRKB-Ur6CYvQ",
        "outputId": "b7aceaa7-9d39-492b-d635-2795232a44da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/13)\u001b[K\rremote: Counting objects:  15% (2/13)\u001b[K\rremote: Counting objects:  23% (3/13)\u001b[K\rremote: Counting objects:  30% (4/13)\u001b[K\rremote: Counting objects:  38% (5/13)\u001b[K\rremote: Counting objects:  46% (6/13)\u001b[K\rremote: Counting objects:  53% (7/13)\u001b[K\rremote: Counting objects:  61% (8/13)\u001b[K\rremote: Counting objects:  69% (9/13)\u001b[K\rremote: Counting objects:  76% (10/13)\u001b[K\rremote: Counting objects:  84% (11/13)\u001b[K\rremote: Counting objects:  92% (12/13)\u001b[K\rremote: Counting objects: 100% (13/13)\u001b[K\rremote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 9 (delta 7), reused 9 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  11% (1/9)\rUnpacking objects:  22% (2/9)\rUnpacking objects:  33% (3/9)\rUnpacking objects:  44% (4/9)\rUnpacking objects:  55% (5/9)\rUnpacking objects:  66% (6/9)\rUnpacking objects:  77% (7/9)\rUnpacking objects:  88% (8/9)\rUnpacking objects: 100% (9/9)\rUnpacking objects: 100% (9/9), 1.87 KiB | 478.00 KiB/s, done.\n",
            "From https://github.com/Eran-BA/PoT\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   9798f26..1fb1efb  main       -> origin/main\n",
            "Updating 9798f26..1fb1efb\n",
            "Fast-forward\n",
            " experiments/maze_ab_proper_generation.py | 40 \u001b[32m++++++++++++++++++++\u001b[m\u001b[31m------------\u001b[m\n",
            " experiments/maze_hyperparam_search.py    | 36 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m---\u001b[m\n",
            " 2 files changed, 58 insertions(+), 18 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A9bGWRgGB3K5"
      },
      "outputs": [],
      "source": [
        "!python3 experiments/maze_hyperparam_search.py --quick --epochs 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "58l0WbNnB3IV"
      },
      "outputs": [],
      "source": [
        "!python experiments/maze_hyperparam_search.py \\\n",
        "  --maze-size 12 \\\n",
        "  --train 1000 \\\n",
        "  --test 100 \\\n",
        "  --epochs 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5pBHV7OB3FE",
        "outputId": "3bedcdd4-e8ff-4e30-9ef8-b8dd281f8205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading results from: experiments/results/maze_hyperparam_search_12x12.csv\n",
            "\n",
            "================================================================================\n",
            "Summary Statistics\n",
            "================================================================================\n",
            "\n",
            "Total configurations tested: 61\n",
            "\n",
            "PoH Accuracy:\n",
            "  Mean:   64.11%\n",
            "  Std:    28.04%\n",
            "  Min:    0.00%\n",
            "  Max:    93.00%\n",
            "\n",
            "PoH Optimality:\n",
            "  Mean:   44.43%\n",
            "  Std:    37.49%\n",
            "  Min:    0.00%\n",
            "  Max:    85.00%\n",
            "\n",
            "Baseline Accuracy:\n",
            "  Mean:   0.85%\n",
            "  Std:    6.66%\n",
            "\n",
            "Baseline Optimality:\n",
            "  Mean:   0.69%\n",
            "  Std:    5.38%\n",
            "\n",
            "\n",
            "================================================================================\n",
            "BEST OVERALL CONFIGURATION (weighted: 70% acc + 30% opt)\n",
            "================================================================================\n",
            "\n",
            "R=2, T=4, n_heads=2\n",
            "\n",
            "PoH-HRM Results:\n",
            "  Accuracy:   93.00%\n",
            "  Optimality: 85.00%\n",
            "  Score:      90.60\n",
            "\n",
            "Baseline Results:\n",
            "  Accuracy:   0.00%\n",
            "  Optimality: 0.00%\n",
            "\n",
            "Improvement:\n",
            "  Accuracy:   0.0%\n",
            "  Optimality: 0.0%\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Top 5 Configurations by poh_acc\n",
            "================================================================================\n",
            "\n",
            "1. R=2, T=4, heads=2\n",
            "   PoH: Acc=93.00%, Opt=85.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "2. R=4, T=8, heads=8\n",
            "   PoH: Acc=93.00%, Opt=84.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "3. R=8, T=2, heads=2\n",
            "   PoH: Acc=92.00%, Opt=83.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "4. R=4, T=4, heads=8\n",
            "   PoH: Acc=91.00%, Opt=85.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "5. R=6, T=8, heads=2\n",
            "   PoH: Acc=91.00%, Opt=80.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Top 5 Configurations by poh_opt\n",
            "================================================================================\n",
            "\n",
            "1. R=2, T=4, heads=2\n",
            "   PoH: Acc=93.00%, Opt=85.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "2. R=4, T=4, heads=8\n",
            "   PoH: Acc=91.00%, Opt=85.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "3. R=4, T=8, heads=8\n",
            "   PoH: Acc=93.00%, Opt=84.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "4. R=8, T=2, heads=2\n",
            "   PoH: Acc=92.00%, Opt=83.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "5. R=2, T=4, heads=4\n",
            "   PoH: Acc=90.00%, Opt=82.00%\n",
            "   Baseline: Acc=0.00%, Opt=0.00%\n",
            "   Improvement: Acc=0.0%, Opt=0.0%\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Analysis by R (metric: poh_acc)\n",
            "================================================================================\n",
            "\n",
            "        mean        std  count\n",
            "R                             \n",
            "8  86.111111   3.443996      9\n",
            "6  84.222222   3.961621      9\n",
            "4  61.111111  28.420972     18\n",
            "2  53.250000  28.076371     24\n",
            "1   0.000000        NaN      1\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Analysis by T (metric: poh_acc)\n",
            "================================================================================\n",
            "\n",
            "        mean        std  count\n",
            "T                             \n",
            "8  68.000000  28.899420     18\n",
            "2  64.619048  25.488186     21\n",
            "4  63.333333  27.920124     21\n",
            "1   0.000000        NaN      1\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Analysis by n_heads (metric: poh_acc)\n",
            "================================================================================\n",
            "\n",
            "              mean        std  count\n",
            "n_heads                             \n",
            "8        66.000000  25.596052     20\n",
            "2        63.600000  32.023675     20\n",
            "4        62.809524  27.511123     21\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ANALYSIS COMPLETE\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python experiments/analyze_maze_hyperparam_results.py \\\n",
        "  experiments/results/maze_hyperparam_search_12x12.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QGo_NWadB27t",
        "outputId": "69601556-9d8f-4624-de5a-917037326ed3"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_77796515-6934-4179-b635-b031c7ee5a0d\", \"maze_hyperparam_search_12x12.csv\", 4901)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Use full path to the CSV file\n",
        "files.download('/content/PoT/experiments/results/maze_hyperparam_search_12x12.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hvYeyptA-Rm"
      },
      "source": [
        "## ðŸš€ Quick Test (Recommended First)\n",
        "\n",
        "**Start here!** Test with challenging 20Ã—20 mazes:\n",
        "- Min path length: 80 (forces long-horizon planning)\n",
        "- Training: 300 mazes, Test: 50 mazes  \n",
        "- Epochs: 30\n",
        "- PoH: R=4, T=4, heads=4\n",
        "\n",
        "**Expected Runtime on A100**: ~45 minutes  \n",
        "**Goal**: Test if proper maze generation provides model differentiation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M76WZZlcA-Rm",
        "outputId": "603a5345-8cf8-45bc-d2b0-24586c7196f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ PoT root: /content/PoT\n",
            "âœ“ maze-dataset library available\n",
            "2025-10-15 01:43:48.344111: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-15 01:43:48.362147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760492628.383778  309456 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760492628.390372  309456 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760492628.407235  309456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760492628.407268  309456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760492628.407273  309456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760492628.407277  309456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 01:43:48.412266: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "âœ“ Successfully imported PoT modules\n",
            "ðŸš€ GPU detected: NVIDIA A100-SXM4-80GB\n",
            "   Memory: 85.17 GB\n",
            "\n",
            "================================================================================\n",
            "MAZE A/B TEST - PROPER GENERATION\n",
            "================================================================================\n",
            "Maze size: 20Ã—20\n",
            "Training mazes: 1000\n",
            "Test mazes: 100\n",
            "Min path length: 80\n",
            "PoH config: R=4, T=8, heads=8\n",
            "Device: cuda\n",
            "================================================================================\n",
            "\n",
            "Generating training data...\n",
            "  Generating 1000 mazes of size 20Ã—20\n",
            "  Minimum path length: 80\n",
            "/usr/local/lib/python3.12/dist-packages/maze_dataset/dataset/maze_dataset.py:544: UserWarning: updating config n_mazes from 3000 to 1396\n",
            "  warnings.warn(\n",
            "  âœ“ Generated 1000 mazes\n",
            "  Path length: 130.2 Â± 36.5 (min=80, max=271)\n",
            "\n",
            "Generating test data...\n",
            "  Generating 100 mazes of size 20Ã—20\n",
            "  Minimum path length: 80\n",
            "/usr/local/lib/python3.12/dist-packages/maze_dataset/dataset/dataset.py:95: UserWarning: in GPTDatasetConfig self.name='maze_20x20_minpath80', self.seed=10042 is trying to override GLOBAL_SEED = 42\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/maze_dataset/dataset/maze_dataset.py:544: UserWarning: updating config n_mazes from 300 to 152\n",
            "  warnings.warn(\n",
            "  âœ“ Generated 100 mazes\n",
            "  Path length: 125.3 Â± 31.4 (min=80, max=214)\n",
            "\n",
            "============================================================\n",
            "Training: Baseline Transformer\n",
            "============================================================\n",
            "Parameters: 6.52M\n",
            "Epoch 10/200, Loss: 5.9979\n",
            "Epoch 20/200, Loss: 5.9914\n",
            "Epoch 30/200, Loss: 5.9880\n",
            "Epoch 40/200, Loss: 5.9858\n",
            "Epoch 50/200, Loss: 5.9858\n",
            "Epoch 60/200, Loss: 5.9843\n",
            "Epoch 70/200, Loss: 5.9843\n",
            "Epoch 80/200, Loss: 5.9846\n",
            "Epoch 90/200, Loss: 5.9835\n",
            "Epoch 100/200, Loss: 5.9842\n",
            "Epoch 110/200, Loss: 5.9842\n",
            "Epoch 120/200, Loss: 5.9832\n",
            "Epoch 130/200, Loss: 5.9853\n",
            "Epoch 140/200, Loss: 5.9836\n",
            "Epoch 150/200, Loss: 5.9845\n",
            "Epoch 160/200, Loss: 5.9834\n",
            "Epoch 170/200, Loss: 5.9833\n",
            "Epoch 180/200, Loss: 5.9844\n",
            "Epoch 190/200, Loss: 5.9839\n",
            "Epoch 200/200, Loss: 5.9827\n",
            "Accuracy: 19.00%, Optimality: 19.00%\n",
            "\n",
            "============================================================\n",
            "Training: PoH-HRM (R=4, T=8)\n",
            "============================================================\n",
            "Parameters: 7.84M\n",
            "Epoch 10/200, Loss: 1.4256\n",
            "Epoch 20/200, Loss: 1.3274\n",
            "Epoch 30/200, Loss: 1.0608\n",
            "Epoch 40/200, Loss: 0.7745\n",
            "Epoch 50/200, Loss: 0.5755\n",
            "Epoch 60/200, Loss: 0.3984\n",
            "Epoch 70/200, Loss: 0.2561\n",
            "Epoch 80/200, Loss: 0.1710\n",
            "Epoch 90/200, Loss: 0.1569\n",
            "Epoch 100/200, Loss: 0.1055\n",
            "Epoch 110/200, Loss: 0.0889\n",
            "Epoch 120/200, Loss: 0.0725\n",
            "Epoch 130/200, Loss: 0.0587\n",
            "Epoch 140/200, Loss: 0.0558\n",
            "Epoch 150/200, Loss: 0.0752\n",
            "Epoch 160/200, Loss: 0.0424\n",
            "Epoch 170/200, Loss: 0.0616\n",
            "Epoch 180/200, Loss: 0.0517\n",
            "Epoch 190/200, Loss: 0.0918\n",
            "Epoch 200/200, Loss: 0.0319\n",
            "Accuracy: 41.00%, Optimality: 34.00%\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "Baseline: Acc=19.00%, Opt=19.00%\n",
            "PoH-HRM:  Acc=41.00%, Opt=34.00%\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 20 \\\n",
        "  --train 1000 \\\n",
        "  --test 100 \\\n",
        "  --min-path-length 80 \\\n",
        "  --epochs 200 \\\n",
        "  --R 4 --T 8 --heads 8 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9MWwbSqwNF2",
        "outputId": "e8cba989-9b9c-4bcb-88ec-3263ef5e9201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ PoT root: /content/PoT\n",
            "âœ“ maze-dataset library available\n",
            "2025-10-15 02:44:28.317957: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-15 02:44:28.336164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760496268.358096  324450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760496268.364765  324450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760496268.381617  324450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760496268.381646  324450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760496268.381649  324450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760496268.381652  324450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-15 02:44:28.386601: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "âœ“ Successfully imported PoT modules\n",
            "ðŸš€ GPU detected: NVIDIA A100-SXM4-80GB\n",
            "   Memory: 85.17 GB\n",
            "\n",
            "================================================================================\n",
            "MAZE A/B TEST - PROPER GENERATION\n",
            "================================================================================\n",
            "Maze size: 20Ã—20\n",
            "Training mazes: 1000\n",
            "Test mazes: 100\n",
            "Min path length: 80\n",
            "PoH config: R=8, T=12, heads=8\n",
            "Device: cuda\n",
            "================================================================================\n",
            "\n",
            "Generating training data...\n",
            "  Generating 1000 mazes of size 20Ã—20\n",
            "  Minimum path length: 80\n",
            "/usr/local/lib/python3.12/dist-packages/maze_dataset/dataset/maze_dataset.py:544: UserWarning: updating config n_mazes from 3000 to 1396\n",
            "  warnings.warn(\n",
            "  âœ“ Generated 1000 mazes\n",
            "  Path length: 130.2 Â± 36.5 (min=80, max=271)\n",
            "\n",
            "Generating test data...\n",
            "  Generating 100 mazes of size 20Ã—20\n",
            "  Minimum path length: 80\n",
            "/usr/local/lib/python3.12/dist-packages/maze_dataset/dataset/dataset.py:95: UserWarning: in GPTDatasetConfig self.name='maze_20x20_minpath80', self.seed=10042 is trying to override GLOBAL_SEED = 42\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/maze_dataset/dataset/maze_dataset.py:544: UserWarning: updating config n_mazes from 300 to 152\n",
            "  warnings.warn(\n",
            "  âœ“ Generated 100 mazes\n",
            "  Path length: 125.3 Â± 31.4 (min=80, max=214)\n",
            "\n",
            "============================================================\n",
            "Training: Baseline Transformer\n",
            "============================================================\n",
            "Parameters: 6.52M\n",
            "Epoch 10/100, Loss: 5.9980\n",
            "Epoch 20/100, Loss: 5.9913\n",
            "Epoch 30/100, Loss: 5.9880\n",
            "Epoch 40/100, Loss: 5.9859\n",
            "Epoch 50/100, Loss: 5.9857\n",
            "Epoch 60/100, Loss: 5.9844\n",
            "Epoch 70/100, Loss: 5.9843\n",
            "Epoch 80/100, Loss: 5.9846\n",
            "Epoch 90/100, Loss: 5.9834\n",
            "Epoch 100/100, Loss: 5.9843\n",
            "Accuracy: 31.00%, Optimality: 26.00%\n",
            "\n",
            "============================================================\n",
            "Training: PoH-HRM (R=8, T=12)\n",
            "============================================================\n",
            "Parameters: 7.84M\n",
            "Epoch 10/100, Loss: 1.4259\n",
            "Epoch 20/100, Loss: 1.2847\n",
            "Epoch 30/100, Loss: 0.9568\n",
            "Epoch 40/100, Loss: 0.6699\n",
            "Epoch 50/100, Loss: 0.4261\n",
            "Epoch 60/100, Loss: 0.2535\n",
            "Epoch 70/100, Loss: 0.2004\n",
            "Epoch 80/100, Loss: 0.1049\n",
            "Epoch 90/100, Loss: 0.0716\n",
            "Epoch 100/100, Loss: 0.0774\n",
            "Accuracy: 52.00%, Optimality: 41.00%\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "Baseline: Acc=31.00%, Opt=26.00%\n",
            "PoH-HRM:  Acc=52.00%, Opt=41.00%\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 20 \\\n",
        "  --train 1000 \\\n",
        "  --test 100 \\\n",
        "  --min-path-length 80 \\\n",
        "  --epochs 100 \\\n",
        "  --R 8 --T 12 --heads 8 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbJc3P2iA-Rm"
      },
      "source": [
        "## Medium Test (24Ã—24 Mazes)\n",
        "\n",
        "**More challenging** with larger mazes:\n",
        "- Min path length: 120 (longer planning horizon)\n",
        "- Training: 400 mazes, Test: 80 mazes\n",
        "- Epochs: 35\n",
        "- PoH: R=4, T=4, heads=4\n",
        "\n",
        "**Expected Runtime on A100**: ~70 minutes  \n",
        "**Goal**: Test if gap increases with maze complexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV0ggwUTA-Rm"
      },
      "outputs": [],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 24 \\\n",
        "  --train 1000 \\\n",
        "  --test 100 \\\n",
        "  --min-path-length 120 \\\n",
        "  --epochs 200 \\\n",
        "  --R 4 --T 8 --heads 8 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SclfZoBKA-Rm"
      },
      "source": [
        "## Hard Test (30Ã—30 Mazes)\n",
        "\n",
        "**Maximum challenge** - test extreme long-horizon planning:\n",
        "- Min path length: 180 (extreme planning horizon)\n",
        "- Training: 500 mazes, Test: 100 mazes\n",
        "- Epochs: 40\n",
        "- PoH: R=4, T=4, heads=4\n",
        "\n",
        "**Expected Runtime on A100**: ~2 hours  \n",
        "**Goal**: Test if HRM advantage scales to very large mazes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5L7ukPlA-Rm"
      },
      "outputs": [],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 30 \\\n",
        "  --train 500 \\\n",
        "  --test 100 \\\n",
        "  --min-path-length 180 \\\n",
        "  --epochs 40 \\\n",
        "  --R 4 --T 4 --heads 4 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hz6UiQEA-Rn"
      },
      "source": [
        "## Adjusting Difficulty\n",
        "\n",
        "If you need to tune maze difficulty based on results, modify `--min-path-length`:\n",
        "\n",
        "**If both models get >95% accuracy:**\n",
        "- Mazes are too easy\n",
        "- Increase `--min-path-length` by 20-40\n",
        "- Example: Change 80 â†’ 100 or 120\n",
        "\n",
        "**If both models get <50% accuracy:**\n",
        "- Mazes are too hard  \n",
        "- Decrease `--min-path-length` by 20-40\n",
        "- Example: Change 80 â†’ 60 or 50\n",
        "\n",
        "**Goal:** Find difficulty where models show clear differentiation (not both 100% or both failing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "APuyqWwzA-Rn"
      },
      "outputs": [],
      "source": [
        "# Example: Custom difficulty adjustment\n",
        "# If 20Ã—20 with min_path=80 is too easy/hard, try:\n",
        "\n",
        "# Easier (shorter paths):\n",
        "# !python experiments/maze_ab_proper_generation.py --maze-size 20 --train 300 --test 50 --min-path-length 60 --epochs 30 --R 4 --T 4 --heads 4\n",
        "\n",
        "# Harder (longer paths):\n",
        "# !python experiments/maze_ab_proper_generation.py --maze-size 20 --train 300 --test 50 --min-path-length 120 --epochs 30 --R 4 --T 4 --heads 4\n",
        "\n",
        "# Different size with auto path length (40% of grid):\n",
        "# !python experiments/maze_ab_proper_generation.py --maze-size 25 --train 400 --test 80 --min-path-length 250 --epochs 35 --R 4 --T 4 --heads 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmHpLOFCA-Rn"
      },
      "source": [
        "## ðŸ“Š Interpreting Results\n",
        "\n",
        "After running the benchmark, look for this in the console output:\n",
        "\n",
        "**Console Output Format:**\n",
        "```\n",
        "Baseline: Acc=XX.X%, Opt=XX.X%\n",
        "PoH-HRM:  Acc=XX.X%, Opt=XX.X%\n",
        "```\n",
        "\n",
        "**Key Metrics:**\n",
        "- **Accuracy**: Did the model find a path to the goal?\n",
        "- **Optimality**: Did it find the shortest path?\n",
        "- **Path Length**: Average solution length in the dataset\n",
        "\n",
        "**What to Analyze:**\n",
        "- **Gap size**: How much better (or worse) is PoH-HRM vs Baseline?\n",
        "- **Trends**: Does the gap change with maze size?\n",
        "- **Absolute performance**: Are mazes at appropriate difficulty level?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etLv0ZqDA-Rn",
        "outputId": "551104c5-f1c2-42d6-b5fc-38ed0226a448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check the console output above for complete results!\n"
          ]
        }
      ],
      "source": [
        "# Check console output above for results\n",
        "# The script prints a summary like:\n",
        "#\n",
        "# ============================================================\n",
        "# Training: Baseline (Transformer)\n",
        "# ============================================================\n",
        "# Parameters: X.XXM\n",
        "# Epoch 30/30 | Loss: X.XXXX | Acc: XX.XX% | Opt: XX.XX%\n",
        "#\n",
        "# Final Performance:\n",
        "#   Accuracy: XX.XX%\n",
        "#   Optimality: XX.XX%\n",
        "#\n",
        "# ============================================================\n",
        "# Training: PoH-HRM (R=4, T=4)\n",
        "# ============================================================\n",
        "# Parameters: X.XXM\n",
        "# Epoch 30/30 | Loss: X.XXXX | Acc: XX.XX% | Opt: XX.XX%\n",
        "#\n",
        "# Final Performance:\n",
        "#   Accuracy: XX.XX%\n",
        "#   Optimality: XX.XX%\n",
        "\n",
        "print(\"Check the console output above for complete results!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "x1KIfVDMA-Rn"
      },
      "outputs": [],
      "source": [
        "# Optional: Save your actual results to a file for later analysis\n",
        "# After running the test, update this with your real numbers:\n",
        "\n",
        "results_text = \"\"\"\n",
        "Maze A/B Test Results\n",
        "======================\n",
        "\n",
        "Test Configuration:\n",
        "- Maze Size: [YOUR_SIZE]\n",
        "- Min Path Length: [YOUR_MIN_PATH]\n",
        "- Training Samples: [YOUR_TRAIN]\n",
        "- Test Samples: [YOUR_TEST]\n",
        "\n",
        "Results:\n",
        "- Baseline:  Acc=[X]%, Opt=[Y]%\n",
        "- PoH-HRM:   Acc=[X]%, Opt=[Y]%\n",
        "- Improvement: [calculate difference]\n",
        "\n",
        "Conclusion: [Your analysis here]\n",
        "\"\"\"\n",
        "\n",
        "# Uncomment to save:\n",
        "# with open('maze_results_summary.txt', 'w') as f:\n",
        "#     f.write(results_text)\n",
        "# print(\"Results saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbXRzTbyA-Rn"
      },
      "source": [
        "## Why HRM Might Help on Long-Horizon Planning\n",
        "\n",
        "### The Architecture:\n",
        "\n",
        "**PoH-HRM** uses a two-timescale recurrent controller:\n",
        "- **f_L (fast module)**: Updates every step, handles local navigation\n",
        "- **f_H (slow module)**: Updates every T=4 steps, guides overall strategy\n",
        "\n",
        "**Baseline** uses flat attention:\n",
        "- All reasoning happens at one timescale\n",
        "- No hierarchical decomposition\n",
        "\n",
        "### The Hypothesis:\n",
        "\n",
        "On mazes with 80+ step solutions:\n",
        "- **Baseline**: Must plan entire path in one shot â†’ potentially harder\n",
        "- **PoH-HRM**: f_H sets high-level direction, f_L executes â†’ potentially easier\n",
        "\n",
        "This is the hypothesis from the [HRM paper](https://arxiv.org/pdf/2506.21734): hierarchical reasoning should help on tasks requiring long-horizon planning.\n",
        "\n",
        "### What to Look For:\n",
        "\n",
        "- **Accuracy gap** favoring PoH-HRM  \n",
        "- **Gap may increase** with maze size (20â†’24â†’30)  \n",
        "- **Optimality difference** (which model finds shorter paths?)\n",
        "\n",
        "**Note:** These are predictions - run the experiments to see if they hold!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln5sLYuDA-Rn"
      },
      "source": [
        "## Export Results\n",
        "\n",
        "Download results to include in paper/documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzWjUs8AA-Rn"
      },
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "files.download('experiments/results/maze_scaling_full.json')\n",
        "files.download('experiments/results/maze_scaling_full.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdzpkgb9rKTM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
