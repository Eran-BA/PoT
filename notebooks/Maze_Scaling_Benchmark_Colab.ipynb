{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§© Maze Scaling Benchmark\n",
        "\n",
        "**Following HRM Paper Protocol (arXiv 2506.21734)**\n",
        "\n",
        "This notebook benchmarks model performance across **increasing maze sizes (8Ã—8 to 30Ã—30)** to test hierarchical reasoning at scale.\n",
        "\n",
        "## Models Compared:\n",
        "- **Baseline**: Standard Transformer encoder-decoder\n",
        "- **BERT**: Pre-trained BERT architecture (parameter-matched)\n",
        "- **PoH-HRM**: Pointer-over-Heads with Hierarchical Reasoning Module\n",
        "\n",
        "## Benchmark Protocol:\n",
        "- **Maze Sizes**: 8Ã—8, 12Ã—12, 16Ã—16, 20Ã—20, 24Ã—24, 30Ã—30\n",
        "- **Training Data**: 1,000 mazes per size (following HRM paper)\n",
        "- **Test Data**: 200 mazes per size\n",
        "- **Task**: Find shortest path from start to goal\n",
        "- **Metrics**: Path finding accuracy & path optimality\n",
        "\n",
        "## Expected Results:\n",
        "HRM's hierarchical reasoning (f_L + f_H) should excel on **larger mazes** (20Ã—20+) where multi-step planning is critical.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets scipy numpy tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
        "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\" if torch.cuda.is_available() else \"N/A\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Full Scaling Benchmark\n",
        "\n",
        "**Default Configuration** (HRM Paper Protocol):\n",
        "- Maze sizes: 8, 12, 16, 20, 24, 30\n",
        "- 1,000 training mazes per size\n",
        "- 200 test mazes per size\n",
        "- 50 epochs per size\n",
        "- PoH: R=4, T=4\n",
        "\n",
        "**Expected Runtime on A100**: ~3-4 hours for full benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 8 12 16 20 24 30 \\\n",
        "  --train 1000 \\\n",
        "  --test 200 \\\n",
        "  --R 4 \\\n",
        "  --T 4 \\\n",
        "  --heads 4 \\\n",
        "  --epochs 50 \\\n",
        "  --seed 42 \\\n",
        "  --output experiments/results/maze_scaling_full\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Scaling Test (Faster)\n",
        "\n",
        "**Reduced Configuration** for faster iteration:\n",
        "- Maze sizes: 8, 12, 16, 20\n",
        "- 500 training mazes per size\n",
        "- 100 test mazes per size\n",
        "- 30 epochs per size\n",
        "\n",
        "**Expected Runtime on A100**: ~45-60 minutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 8 12 16 20 \\\n",
        "  --train 500 \\\n",
        "  --test 100 \\\n",
        "  --R 4 \\\n",
        "  --T 4 \\\n",
        "  --heads 4 \\\n",
        "  --epochs 30 \\\n",
        "  --seed 42 \\\n",
        "  --output experiments/results/maze_scaling_quick\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Large-Scale Test (30Ã—30 Only)\n",
        "\n",
        "**Focus on hardest maze** (30Ã—30) as in HRM paper:\n",
        "- 1,000 training mazes\n",
        "- 200 test mazes\n",
        "- 100 epochs\n",
        "\n",
        "**Expected Runtime on A100**: ~60-90 minutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 30 \\\n",
        "  --train 1000 \\\n",
        "  --test 200 \\\n",
        "  --R 4 \\\n",
        "  --T 4 \\\n",
        "  --heads 4 \\\n",
        "  --epochs 100 \\\n",
        "  --seed 42 \\\n",
        "  --output experiments/results/maze_30x30_benchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n",
        "\n",
        "The benchmark automatically generates:\n",
        "1. **JSON results** with all metrics\n",
        "2. **Scaling plot** showing accuracy/optimality vs maze size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the scaling plot\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Adjust path based on which benchmark you ran\n",
        "display(Image('experiments/results/maze_scaling_full.png'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display JSON results\n",
        "import json\n",
        "\n",
        "with open('experiments/results/maze_scaling_full.json', 'r') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "print(\"Maze Scaling Results:\")\n",
        "print(json.dumps(results, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\n",
        "\n",
        "**Key Questions:**\n",
        "1. Does PoH-HRM outperform baselines on larger mazes (20Ã—20+)?\n",
        "2. How does performance degrade with maze size for each model?\n",
        "3. Does HRM's hierarchical reasoning provide better path optimality?\n",
        "\n",
        "**Expected Findings:**\n",
        "- All models perform well on small mazes (8Ã—8, 12Ã—12)\n",
        "- PoH-HRM should maintain high accuracy on 20Ã—20+ mazes\n",
        "- Baseline/BERT may struggle with longer planning horizons\n",
        "- HRM's temporal abstraction (T=4) helps with multi-step reasoning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Results\n",
        "\n",
        "Download results to include in paper/documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "files.download('experiments/results/maze_scaling_full.json')\n",
        "files.download('experiments/results/maze_scaling_full.png')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
