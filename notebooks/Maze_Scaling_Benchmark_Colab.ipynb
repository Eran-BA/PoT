{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§© Maze Scaling Benchmark - Proper Generation\n",
        "\n",
        "**Using Research-Grade Maze Generation (maze-dataset library)**\n",
        "\n",
        "This notebook uses the [maze-dataset](https://github.com/understanding-search/maze-dataset) library for high-quality maze generation with controllable difficulty.\n",
        "\n",
        "## âœ¨ Key Improvements:\n",
        "- âœ… **Proper algorithms**: DFS, Wilson's, Prim's (we use DFS for challenging mazes)\n",
        "- âœ… **Path length filtering**: Control difficulty by minimum solution length\n",
        "- âœ… **Guaranteed solvable**: No unsolvable mazes\n",
        "- âœ… **Long planning horizons**: Force 80+ step solutions for differentiation\n",
        "\n",
        "## Models Compared:\n",
        "- **Baseline**: Standard Transformer encoder-decoder\n",
        "- **PoH-HRM**: Pointer-over-Heads with Hierarchical Reasoning Module\n",
        "\n",
        "## Why Proper Generation Matters:\n",
        "**Old approach** (random walls): Path length ~16-20 â†’ All models get 100% âŒ  \n",
        "**New approach** (DFS + filtering): Path length 80+ â†’ Clear differentiation âœ…\n",
        "\n",
        "## Recommended Starting Point:\n",
        "- **Maze Size**: 20Ã—20 (large enough to be challenging)\n",
        "- **Min Path Length**: 80 (20% of grid size)\n",
        "- **Training**: 300-500 mazes\n",
        "- **Goal**: Test if HRM provides advantage on long-horizon planning\n",
        "\n",
        "---\n",
        "\n",
        "**Hardware**: Optimized for A100 GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets scipy numpy tqdm matplotlib seaborn\n",
        "\n",
        "# Install maze-dataset library for proper maze generation\n",
        "!pip install maze-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
        "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\" if torch.cuda.is_available() else \"N/A\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Quick Test (Recommended First)\n",
        "\n",
        "**Start here!** Test with challenging 20Ã—20 mazes:\n",
        "- Min path length: 80 (forces long-horizon planning)\n",
        "- Training: 300 mazes, Test: 50 mazes  \n",
        "- Epochs: 30\n",
        "- PoH: R=4, T=4, heads=4\n",
        "\n",
        "**Expected Runtime on A100**: ~45 minutes  \n",
        "**Goal**: Test if proper maze generation provides model differentiation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 20 \\\n",
        "  --train 300 \\\n",
        "  --test 50 \\\n",
        "  --min-path-length 80 \\\n",
        "  --epochs 30 \\\n",
        "  --R 4 --T 4 --heads 4 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Medium Test (24Ã—24 Mazes)\n",
        "\n",
        "**More challenging** with larger mazes:\n",
        "- Min path length: 120 (longer planning horizon)\n",
        "- Training: 400 mazes, Test: 80 mazes\n",
        "- Epochs: 35\n",
        "- PoH: R=4, T=4, heads=4\n",
        "\n",
        "**Expected Runtime on A100**: ~70 minutes  \n",
        "**Goal**: Test if gap increases with maze complexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 24 \\\n",
        "  --train 400 \\\n",
        "  --test 80 \\\n",
        "  --min-path-length 120 \\\n",
        "  --epochs 35 \\\n",
        "  --R 4 --T 4 --heads 4 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hard Test (30Ã—30 Mazes)\n",
        "\n",
        "**Maximum challenge** - test extreme long-horizon planning:\n",
        "- Min path length: 180 (extreme planning horizon)\n",
        "- Training: 500 mazes, Test: 100 mazes\n",
        "- Epochs: 40\n",
        "- PoH: R=4, T=4, heads=4\n",
        "\n",
        "**Expected Runtime on A100**: ~2 hours  \n",
        "**Goal**: Test if HRM advantage scales to very large mazes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_ab_proper_generation.py \\\n",
        "  --maze-size 30 \\\n",
        "  --train 500 \\\n",
        "  --test 100 \\\n",
        "  --min-path-length 180 \\\n",
        "  --epochs 40 \\\n",
        "  --R 4 --T 4 --heads 4 \\\n",
        "  --seed 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adjusting Difficulty\n",
        "\n",
        "If you need to tune maze difficulty based on results, modify `--min-path-length`:\n",
        "\n",
        "**If both models get >95% accuracy:**\n",
        "- Mazes are too easy\n",
        "- Increase `--min-path-length` by 20-40\n",
        "- Example: Change 80 â†’ 100 or 120\n",
        "\n",
        "**If both models get <50% accuracy:**\n",
        "- Mazes are too hard  \n",
        "- Decrease `--min-path-length` by 20-40\n",
        "- Example: Change 80 â†’ 60 or 50\n",
        "\n",
        "**Goal:** Find difficulty where models show clear differentiation (not both 100% or both failing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Custom difficulty adjustment\n",
        "# If 20Ã—20 with min_path=80 is too easy/hard, try:\n",
        "\n",
        "# Easier (shorter paths):\n",
        "# !python experiments/maze_ab_proper_generation.py --maze-size 20 --train 300 --test 50 --min-path-length 60 --epochs 30 --R 4 --T 4 --heads 4\n",
        "\n",
        "# Harder (longer paths):  \n",
        "# !python experiments/maze_ab_proper_generation.py --maze-size 20 --train 300 --test 50 --min-path-length 120 --epochs 30 --R 4 --T 4 --heads 4\n",
        "\n",
        "# Different size with auto path length (40% of grid):\n",
        "# !python experiments/maze_ab_proper_generation.py --maze-size 25 --train 400 --test 80 --min-path-length 250 --epochs 35 --R 4 --T 4 --heads 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Interpreting Results\n",
        "\n",
        "After running the benchmark, look for this in the console output:\n",
        "\n",
        "**Console Output Format:**\n",
        "```\n",
        "Baseline: Acc=XX.X%, Opt=XX.X%\n",
        "PoH-HRM:  Acc=XX.X%, Opt=XX.X%\n",
        "```\n",
        "\n",
        "**Key Metrics:**\n",
        "- **Accuracy**: Did the model find a path to the goal?\n",
        "- **Optimality**: Did it find the shortest path?\n",
        "- **Path Length**: Average solution length in the dataset\n",
        "\n",
        "**What to Analyze:**\n",
        "- **Gap size**: How much better (or worse) is PoH-HRM vs Baseline?\n",
        "- **Trends**: Does the gap change with maze size?\n",
        "- **Absolute performance**: Are mazes at appropriate difficulty level?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check console output above for results\n",
        "# The script prints a summary like:\n",
        "#\n",
        "# ============================================================\n",
        "# Training: Baseline (Transformer)\n",
        "# ============================================================\n",
        "# Parameters: X.XXM\n",
        "# Epoch 30/30 | Loss: X.XXXX | Acc: XX.XX% | Opt: XX.XX%\n",
        "# \n",
        "# Final Performance:\n",
        "#   Accuracy: XX.XX%\n",
        "#   Optimality: XX.XX%\n",
        "#\n",
        "# ============================================================\n",
        "# Training: PoH-HRM (R=4, T=4)\n",
        "# ============================================================\n",
        "# Parameters: X.XXM\n",
        "# Epoch 30/30 | Loss: X.XXXX | Acc: XX.XX% | Opt: XX.XX%\n",
        "#\n",
        "# Final Performance:\n",
        "#   Accuracy: XX.XX%\n",
        "#   Optimality: XX.XX%\n",
        "\n",
        "print(\"Check the console output above for complete results!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Save your actual results to a file for later analysis\n",
        "# After running the test, update this with your real numbers:\n",
        "\n",
        "results_text = \"\"\"\n",
        "Maze A/B Test Results\n",
        "======================\n",
        "\n",
        "Test Configuration:\n",
        "- Maze Size: [YOUR_SIZE]\n",
        "- Min Path Length: [YOUR_MIN_PATH]\n",
        "- Training Samples: [YOUR_TRAIN]\n",
        "- Test Samples: [YOUR_TEST]\n",
        "\n",
        "Results:\n",
        "- Baseline:  Acc=[X]%, Opt=[Y]%\n",
        "- PoH-HRM:   Acc=[X]%, Opt=[Y]%\n",
        "- Improvement: [calculate difference]\n",
        "\n",
        "Conclusion: [Your analysis here]\n",
        "\"\"\"\n",
        "\n",
        "# Uncomment to save:\n",
        "# with open('maze_results_summary.txt', 'w') as f:\n",
        "#     f.write(results_text)\n",
        "# print(\"Results saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why HRM Might Help on Long-Horizon Planning\n",
        "\n",
        "### The Architecture:\n",
        "\n",
        "**PoH-HRM** uses a two-timescale recurrent controller:\n",
        "- **f_L (fast module)**: Updates every step, handles local navigation\n",
        "- **f_H (slow module)**: Updates every T=4 steps, guides overall strategy\n",
        "\n",
        "**Baseline** uses flat attention:\n",
        "- All reasoning happens at one timescale\n",
        "- No hierarchical decomposition\n",
        "\n",
        "### The Hypothesis:\n",
        "\n",
        "On mazes with 80+ step solutions:\n",
        "- **Baseline**: Must plan entire path in one shot â†’ potentially harder\n",
        "- **PoH-HRM**: f_H sets high-level direction, f_L executes â†’ potentially easier\n",
        "\n",
        "This is the hypothesis from the [HRM paper](https://arxiv.org/pdf/2506.21734): hierarchical reasoning should help on tasks requiring long-horizon planning.\n",
        "\n",
        "### What to Look For:\n",
        "\n",
        "- **Accuracy gap** favoring PoH-HRM  \n",
        "- **Gap may increase** with maze size (20â†’24â†’30)  \n",
        "- **Optimality difference** (which model finds shorter paths?)\n",
        "\n",
        "**Note:** These are predictions - run the experiments to see if they hold!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Results\n",
        "\n",
        "Download results to include in paper/documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "files.download('experiments/results/maze_scaling_full.json')\n",
        "files.download('experiments/results/maze_scaling_full.png')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
