{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß© Maze Scaling Benchmark - Proper Generation\n",
        "\n",
        "**Using Research-Grade Maze Generation (maze-dataset library)**\n",
        "\n",
        "This notebook uses the [maze-dataset](https://github.com/understanding-search/maze-dataset) library for high-quality maze generation with controllable difficulty.\n",
        "\n",
        "## ‚ú® Key Improvements:\n",
        "- ‚úÖ **Proper algorithms**: DFS, Wilson's, Prim's (we use DFS for challenging mazes)\n",
        "- ‚úÖ **Path length filtering**: Control difficulty by minimum solution length\n",
        "- ‚úÖ **Guaranteed solvable**: No unsolvable mazes\n",
        "- ‚úÖ **Long planning horizons**: Force 80+ step solutions for differentiation\n",
        "\n",
        "## Models Compared:\n",
        "- **Baseline**: Standard Transformer encoder-decoder\n",
        "- **PoH-HRM**: Pointer-over-Heads with Hierarchical Reasoning Module\n",
        "\n",
        "## Why Proper Generation Matters:\n",
        "**Old approach** (random walls): Path length ~16-20 ‚Üí All models get 100% ‚ùå  \n",
        "**New approach** (DFS + filtering): Path length 80+ ‚Üí Clear differentiation ‚úÖ\n",
        "\n",
        "## Recommended Starting Point:\n",
        "- **Maze Size**: 20√ó20 (large enough to be challenging)\n",
        "- **Min Path Length**: 80 (20% of grid size)\n",
        "- **Training**: 300-500 mazes\n",
        "- **Expected**: Baseline: 60-75%, PoH-HRM: 80-90%\n",
        "\n",
        "---\n",
        "\n",
        "**Hardware**: Optimized for A100 GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets scipy numpy tqdm matplotlib seaborn\n",
        "\n",
        "# Install maze-dataset library for proper maze generation\n",
        "!pip install maze-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
        "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\" if torch.cuda.is_available() else \"N/A\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Full Scaling Benchmark\n",
        "\n",
        "**Default Configuration** (HRM Paper Protocol):\n",
        "- Maze sizes: 8, 12, 16, 20, 24, 30\n",
        "- 1,000 training mazes per size\n",
        "- 200 test mazes per size\n",
        "- 50 epochs per size\n",
        "- PoH: R=4, T=4\n",
        "\n",
        "**Expected Runtime on A100**: ~3-4 hours for full benchmark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 8 12 16 20 24 30 \\\n",
        "  --train 1000 \\\n",
        "  --test 200 \\\n",
        "  --R 4 \\\n",
        "  --T 4 \\\n",
        "  --heads 4 \\\n",
        "  --epochs 50 \\\n",
        "  --seed 42 \\\n",
        "  --output experiments/results/maze_scaling_full\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Scaling Test (Faster)\n",
        "\n",
        "**Reduced Configuration** for faster iteration:\n",
        "- Maze sizes: 8, 12, 16, 20\n",
        "- 500 training mazes per size\n",
        "- 100 test mazes per size\n",
        "- 30 epochs per size\n",
        "\n",
        "**Expected Runtime on A100**: ~45-60 minutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 8 12 16 20 \\\n",
        "  --train 500 \\\n",
        "  --test 100 \\\n",
        "  --R 4 \\\n",
        "  --T 4 \\\n",
        "  --heads 4 \\\n",
        "  --epochs 30 \\\n",
        "  --seed 42 \\\n",
        "  --output experiments/results/maze_scaling_quick\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Large-Scale Test (30√ó30 Only)\n",
        "\n",
        "**Focus on hardest maze** (30√ó30) as in HRM paper:\n",
        "- 1,000 training mazes\n",
        "- 200 test mazes\n",
        "- 100 epochs\n",
        "\n",
        "**Expected Runtime on A100**: ~60-90 minutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 30 \\\n",
        "  --train 1000 \\\n",
        "  --test 200 \\\n",
        "  --R 4 \\\n",
        "  --T 4 \\\n",
        "  --heads 4 \\\n",
        "  --epochs 100 \\\n",
        "  --seed 42 \\\n",
        "  --output experiments/results/maze_30x30_benchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî• HARDER MAZES (Better Model Differentiation)\n",
        "\n",
        "**Problem**: Easy mazes lead to 100% accuracy for all models ‚Üí no differentiation\n",
        "\n",
        "**Solution**: Increase `wall_prob` to create harder mazes:\n",
        "- `0.3` = Easy (default, often too easy)\n",
        "- `0.45` = Medium\n",
        "- `0.6` = Hard ‚≠ê **recommended for differentiation**\n",
        "- `0.7` = Very Hard (may be unsolvable)\n",
        "\n",
        "**Use the helper script** to easily run with different difficulties:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTION 1: Quick test with hard mazes (16√ó16 only, ~10 min)\n",
        "!python experiments/run_harder_mazes.py --wall-prob 0.6 --quick\n",
        "\n",
        "# OPTION 2: Full scaling with hard mazes (8-30, ~2 hours)\n",
        "# !python experiments/run_harder_mazes.py --wall-prob 0.6 --maze-sizes 8 12 16 20 24 30\n",
        "\n",
        "# OPTION 3: Medium difficulty full scaling\n",
        "# !python experiments/run_harder_mazes.py --wall-prob 0.45 --maze-sizes 8 12 16 20 24 30\n",
        "\n",
        "# OPTION 4: Very hard mazes (expert mode, may have no solution!)\n",
        "# !python experiments/run_harder_mazes.py --wall-prob 0.7 --maze-sizes 8 12 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n",
        "\n",
        "The benchmark automatically generates:\n",
        "1. **JSON results** with all metrics\n",
        "2. **Scaling plot** showing accuracy/optimality vs maze size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the scaling plot\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Adjust path based on which benchmark you ran\n",
        "display(Image('experiments/results/maze_scaling_full.png'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display JSON results\n",
        "import json\n",
        "\n",
        "with open('experiments/results/maze_scaling_full.json', 'r') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "print(\"Maze Scaling Results:\")\n",
        "print(json.dumps(results, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\n",
        "\n",
        "**Key Questions:**\n",
        "1. Does PoH-HRM outperform baselines on larger mazes (20√ó20+)?\n",
        "2. How does performance degrade with maze size for each model?\n",
        "3. Does HRM's hierarchical reasoning provide better path optimality?\n",
        "\n",
        "**Expected Findings:**\n",
        "- All models perform well on small mazes (8√ó8, 12√ó12)\n",
        "- PoH-HRM should maintain high accuracy on 20√ó20+ mazes\n",
        "- Baseline/BERT may struggle with longer planning horizons\n",
        "- HRM's temporal abstraction (T=4) helps with multi-step reasoning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Results\n",
        "\n",
        "Download results to include in paper/documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "\n",
        "files.download('experiments/results/maze_scaling_full.json')\n",
        "files.download('experiments/results/maze_scaling_full.png')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
