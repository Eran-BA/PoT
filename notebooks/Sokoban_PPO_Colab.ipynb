{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sokoban PPO Benchmark - Pointer-Over-Heads Transformer\n",
        "\n",
        "This notebook runs the Sokoban PPO benchmark with PoT iterative refinement.\n",
        "\n",
        "**Training modes:**\n",
        "- `heuristic`: Pretrain with heuristic pseudo-labels\n",
        "- `ppo`: Pure PPO training\n",
        "- `combined`: Pretrain + PPO fine-tuning\n",
        "\n",
        "**Augmentations:** Geometric symmetries (flip, rotate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository and install dependencies\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n",
        "!pip install -q torch numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Heuristic Training WITH Augmentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heuristic training WITH augmentations (geometric symmetries)\n",
        "!python experiments/sokoban_pot_benchmark.py \\\n",
        "    --mode heuristic \\\n",
        "    --download \\\n",
        "    --model-type pot \\\n",
        "    --R 4 \\\n",
        "    --d-model 256 \\\n",
        "    --n-heads 4 \\\n",
        "    --n-layers 2 \\\n",
        "    --controller-type transformer \\\n",
        "    --max-depth 32 \\\n",
        "    --heuristic-epochs 10 \\\n",
        "    --batch-size 64 \\\n",
        "    --learning-rate 1e-4 \\\n",
        "    --warmup-steps 100 \\\n",
        "    --eval-interval 2 \\\n",
        "    --output-dir experiments/results/sokoban_heuristic_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Heuristic Training WITHOUT Augmentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heuristic training WITHOUT augmentations\n",
        "!python experiments/sokoban_pot_benchmark.py \\\n",
        "    --mode heuristic \\\n",
        "    --model-type pot \\\n",
        "    --R 4 \\\n",
        "    --d-model 256 \\\n",
        "    --n-heads 4 \\\n",
        "    --n-layers 2 \\\n",
        "    --controller-type transformer \\\n",
        "    --max-depth 32 \\\n",
        "    --no-augment \\\n",
        "    --heuristic-epochs 10 \\\n",
        "    --batch-size 64 \\\n",
        "    --learning-rate 1e-4 \\\n",
        "    --warmup-steps 100 \\\n",
        "    --eval-interval 2 \\\n",
        "    --output-dir experiments/results/sokoban_heuristic_no_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PPO training WITH augmentations\n",
        "!python experiments/sokoban_pot_benchmark.py \\\n",
        "    --mode ppo \\\n",
        "    --model-type pot \\\n",
        "    --R 4 \\\n",
        "    --d-model 256 \\\n",
        "    --n-heads 4 \\\n",
        "    --n-layers 2 \\\n",
        "    --controller-type transformer \\\n",
        "    --max-depth 32 \\\n",
        "    --ppo-timesteps 100000 \\\n",
        "    --ppo-n-envs 8 \\\n",
        "    --batch-size 64 \\\n",
        "    --learning-rate 3e-4 \\\n",
        "    --output-dir experiments/results/sokoban_ppo_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Display Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "result_dirs = [\n",
        "    ('Heuristic + Aug', 'experiments/results/sokoban_heuristic_aug'),\n",
        "    ('Heuristic - No Aug', 'experiments/results/sokoban_heuristic_no_aug'),\n",
        "    ('PPO + Aug', 'experiments/results/sokoban_ppo_aug'),\n",
        "]\n",
        "\n",
        "for name, d in result_dirs:\n",
        "    results_file = Path(d) / 'results.json'\n",
        "    if results_file.exists():\n",
        "        with open(results_file) as f:\n",
        "            results = json.load(f)\n",
        "        print(f\"\\n=== {name} ===\")\n",
        "        if 'evaluation' in results:\n",
        "            e = results['evaluation']\n",
        "            print(f\"Solve Rate @50:  {e.get('solve_rate@50', 0):.2%}\")\n",
        "            print(f\"Solve Rate @100: {e.get('solve_rate@100', 0):.2%}\")\n",
        "            print(f\"Solve Rate @200: {e.get('solve_rate@200', 0):.2%}\")\n",
        "            print(f\"Median Steps:    {e.get('median_steps', 0):.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
