{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ® Sokoban Supervised Learning with PoT\n",
        "\n",
        "This notebook trains a **Pondering over Thoughts (PoT)** model on Sokoban puzzles using **supervised learning** - identical to our Sudoku training pipeline.\n",
        "\n",
        "## What is Sokoban?\n",
        "\n",
        "**Sokoban** (å€‰åº«ç•ª, \"warehouse keeper\") is a classic puzzle game where you push boxes onto target locations.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4b/Sokoban_ani.gif\" width=\"300\" alt=\"Sokoban gameplay animation\">\n",
        "\n",
        "**Rules:**\n",
        "- ğŸ§‘ Player can move in 4 directions (up/down/left/right)\n",
        "- ğŸ“¦ Player can push ONE box at a time (not pull)\n",
        "- ğŸ¯ Goal: Push ALL boxes onto target squares\n",
        "- âš ï¸ Boxes can get stuck in corners (deadlock = game over!)\n",
        "\n",
        "â–¶ï¸ **Watch gameplay:** [Sokoban Tutorial on YouTube](https://www.youtube.com/watch?v=4SjXQ_bHTxU)\n",
        "\n",
        "**Why is it hard for AI?**\n",
        "- PSPACE-complete (exponential state space)\n",
        "- Sparse rewards (only get reward when solved)\n",
        "- Long-horizon planning required\n",
        "- Easy to create unsolvable states\n",
        "\n",
        "## Benchmark Comparison\n",
        "\n",
        "| Method | Simple (6Ã—6, 1 box) | Complex (10Ã—10, 2 boxes) | Notes |\n",
        "|--------|---------------------|--------------------------|-------|\n",
        "| SFT (paper) | ~50% | ~15% | Supervised fine-tuning |\n",
        "| GPT-4 + LangGraph | varies | varies | [Blog](https://blog.gopenai.com/using-llms-and-langgraph-to-tackle-sokoban-puzzles-5f50b43b9515) |\n",
        "| RL (PPO) | ~20% | <5% | Very hard to train |\n",
        "| Random | 25% | 25% | 4 actions |\n",
        "| **PoT (this notebook)** | TBD | TBD | Adaptive depth |\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We use the [Xiaofeng77/sokoban](https://huggingface.co/datasets/Xiaofeng77/sokoban) HuggingFace dataset with:\n",
        "- ~3,000 (board, optimal_action) pairs\n",
        "- On-the-fly augmentation (8x via rotations/flips)\n",
        "- Cross-entropy loss + Q-halt loss (identical to Sudoku)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ”§ Setup (Run First)\n",
        "# @markdown Install dependencies and clone repository\n",
        "\n",
        "!pip install -q torch datasets tqdm wandb gym-sokoban\n",
        "\n",
        "# Clone PoT repository\n",
        "!git clone -q https://github.com/ebenartzy/PoT.git 2>/dev/null || (cd PoT && git pull -q)\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, 'PoT')\n",
        "\n",
        "print(\"âœ… Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ“Š Configuration\n",
        "# @markdown Adjust training parameters\n",
        "\n",
        "MODEL_TYPE = \"pot\"  # @param [\"pot\", \"hybrid_pot\", \"baseline\"]\n",
        "R = 4  # @param {type:\"slider\", min:1, max:8, step:1}\n",
        "EPOCHS = 30  # @param {type:\"slider\", min:5, max:100, step:5}\n",
        "BATCH_SIZE = 64  # @param {type:\"slider\", min:16, max:128, step:16}\n",
        "LEARNING_RATE = 1e-4  # @param {type:\"number\"}\n",
        "AUGMENT = True  # @param {type:\"boolean\"}\n",
        "USE_WANDB = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# Evaluation difficulties\n",
        "EVAL_DIFFICULTIES = [\"simple\", \"complex\"]  # Easy (6x6,1box) and Hard (10x10,2boxes)\n",
        "EVAL_SAMPLES = 200\n",
        "\n",
        "print(f\"Config: {MODEL_TYPE}, R={R}, epochs={EPOCHS}, batch={BATCH_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ“¥ Load Dataset\n",
        "# @markdown Downloads Sokoban dataset from HuggingFace\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from src.data.sokoban_hf import SokobanHFDataset\n",
        "\n",
        "# Load datasets\n",
        "print(\"Loading HuggingFace Sokoban dataset...\")\n",
        "train_ds = SokobanHFDataset(data_dir=\".\", split=\"train\", augment=AUGMENT)\n",
        "test_ds = SokobanHFDataset(data_dir=\".\", split=\"test\", augment=False)\n",
        "\n",
        "# Split train into train/val\n",
        "val_size = min(500, len(train_ds) // 5)\n",
        "train_size = len(train_ds) - val_size\n",
        "train_subset, val_subset = random_split(\n",
        "    train_ds, [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"âœ… Train: {len(train_subset)}, Val: {len(val_subset)}, Test: {len(test_ds)}\")\n",
        "print(f\"   Board shape: {train_ds.board_shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ—ï¸ Create Model\n",
        "\n",
        "from src.pot.models.sokoban_solver import SokobanPoT, HybridSokobanPoT, SokobanBaseline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "H, W = train_ds.board_shape\n",
        "\n",
        "if MODEL_TYPE == \"pot\":\n",
        "    model = SokobanPoT(\n",
        "        board_height=H,\n",
        "        board_width=W,\n",
        "        d_model=128,\n",
        "        n_heads=4,\n",
        "        n_layers=4,\n",
        "        R=R,\n",
        "        num_actions=4,\n",
        "    )\n",
        "elif MODEL_TYPE == \"hybrid_pot\":\n",
        "    model = HybridSokobanPoT(\n",
        "        board_height=H,\n",
        "        board_width=W,\n",
        "        d_model=128,\n",
        "        n_heads=4,\n",
        "        n_layers=4,\n",
        "        R=R,\n",
        "        num_actions=4,\n",
        "    )\n",
        "else:\n",
        "    model = SokobanBaseline(\n",
        "        board_height=H,\n",
        "        board_width=W,\n",
        "        d_model=128,\n",
        "        n_heads=4,\n",
        "        n_layers=4,\n",
        "        num_actions=4,\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"âœ… {MODEL_TYPE} model: {n_params:,} parameters\")\n",
        "print(f\"   Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸš€ Train Model\n",
        "# @markdown Supervised training with cross-entropy + Q-halt loss (identical to Sudoku)\n",
        "\n",
        "from src.training.sokoban_supervised import train_supervised\n",
        "\n",
        "if USE_WANDB:\n",
        "    import wandb\n",
        "    wandb.init(project=\"sokoban-pot\", name=f\"{MODEL_TYPE}-R{R}\")\n",
        "\n",
        "results = train_supervised(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    epochs=EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=1e-4,\n",
        "    grad_clip=1.0,\n",
        "    warmup_steps=100,\n",
        "    use_pot=(MODEL_TYPE != \"baseline\"),\n",
        "    wandb_log=USE_WANDB,\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Training complete!\")\n",
        "print(f\"   Best val accuracy: {results['best_val_acc']:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ“ˆ Evaluate on HuggingFace Test Set\n",
        "\n",
        "from src.training.sokoban_supervised import evaluate\n",
        "\n",
        "test_metrics = evaluate(model, test_loader, device)\n",
        "print(f\"\\nğŸ“Š HuggingFace Test Set Results:\")\n",
        "print(f\"   Accuracy: {test_metrics['accuracy']:.2%}\")\n",
        "print(f\"   Loss: {test_metrics['loss']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ¯ Multi-Difficulty Evaluation\n",
        "# @markdown Evaluate on Simple (6Ã—6, 1 box) and Complex (10Ã—10, 2 boxes)\n",
        "\n",
        "from src.data.sokoban_generator import SokobanGeneratedDataset\n",
        "\n",
        "difficulty_results = {}\n",
        "\n",
        "for difficulty in EVAL_DIFFICULTIES:\n",
        "    print(f\"\\nGenerating {difficulty} test boards...\")\n",
        "    \n",
        "    eval_ds = SokobanGeneratedDataset(\n",
        "        difficulty=difficulty,\n",
        "        n_samples=EVAL_SAMPLES,\n",
        "        seed=1042,\n",
        "        augment=False,\n",
        "    )\n",
        "    \n",
        "    eval_loader = DataLoader(eval_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    \n",
        "    # Handle different board sizes\n",
        "    eval_h, eval_w = eval_ds.board_shape\n",
        "    if (eval_h, eval_w) != train_ds.board_shape:\n",
        "        print(f\"   âš ï¸ Board size mismatch: train={train_ds.board_shape}, eval={eval_ds.board_shape}\")\n",
        "        print(f\"   Skipping (model trained on fixed size)\")\n",
        "        difficulty_results[difficulty] = {'accuracy': None, 'note': 'size_mismatch'}\n",
        "        continue\n",
        "    \n",
        "    eval_metrics = evaluate(model, eval_loader, device)\n",
        "    difficulty_results[difficulty] = {\n",
        "        'accuracy': eval_metrics['accuracy'],\n",
        "        'loss': eval_metrics['loss'],\n",
        "    }\n",
        "    print(f\"   {difficulty}: {eval_metrics['accuracy']:.2%} accuracy\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"MULTI-DIFFICULTY RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "for diff, res in difficulty_results.items():\n",
        "    if res.get('accuracy') is not None:\n",
        "        print(f\"  {diff}: {res['accuracy']:.2%}\")\n",
        "    else:\n",
        "        print(f\"  {diff}: N/A ({res.get('note', 'error')})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ“‹ Final Comparison Table\n",
        "\n",
        "simple_acc = difficulty_results.get('simple', {}).get('accuracy', 0) or 0\n",
        "complex_acc = difficulty_results.get('complex', {}).get('accuracy', 0) or 0\n",
        "\n",
        "print(\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘                    SOKOBAN BENCHMARK COMPARISON                          â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘ Method                   â”‚ Simple (6Ã—6,1) â”‚ Complex (10Ã—10,2) â”‚ Notes    â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘ SFT (paper)              â”‚     ~50%       â”‚      ~15%         â”‚ Baseline â•‘\n",
        "â•‘ GPT-4 + LangGraph        â”‚     varies     â”‚      varies       â”‚ Zero-shotâ•‘\n",
        "â•‘ RL (PPO)                 â”‚     ~20%       â”‚      <5%          â”‚ Hard     â•‘\n",
        "â•‘ Random                   â”‚      25%       â”‚       25%         â”‚ 4 actionsâ•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•£\"\"\")\n",
        "\n",
        "print(f\"â•‘ PoT (this run)           â”‚    {simple_acc:5.1%}      â”‚     {complex_acc:5.1%}        â”‚ R={R}      â•‘\")\n",
        "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
        "\n",
        "# Store for benchmark results\n",
        "COLAB_RESULTS = {\n",
        "    'model_type': MODEL_TYPE,\n",
        "    'R': R,\n",
        "    'epochs': EPOCHS,\n",
        "    'best_val_acc': results['best_val_acc'],\n",
        "    'hf_test_acc': test_metrics['accuracy'],\n",
        "    'simple_acc': simple_acc,\n",
        "    'complex_acc': complex_acc,\n",
        "}\n",
        "print(f\"\\nğŸ“Š Results dict: {COLAB_RESULTS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ’¾ Save Model (Optional)\n",
        "\n",
        "import os\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "save_path = f\"checkpoints/sokoban_{MODEL_TYPE}_R{R}.pt\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': {\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'R': R,\n",
        "        'board_shape': train_ds.board_shape,\n",
        "    },\n",
        "    'results': COLAB_RESULTS,\n",
        "}, save_path)\n",
        "\n",
        "print(f\"âœ… Model saved to {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Notes\n",
        "\n",
        "### Loss Function (Identical to Sudoku)\n",
        "```python\n",
        "loss = cross_entropy(action_logits, action_label) + 0.5 * bce(q_halt, is_correct)\n",
        "```\n",
        "\n",
        "### Difficulty Levels\n",
        "| Difficulty | Size | Boxes | Avg Solution Length |\n",
        "|------------|------|-------|---------------------|\n",
        "| simple | 6Ã—6 | 1 | ~4 moves |\n",
        "| larger | 10Ã—10 | 1 | ~15 moves |\n",
        "| two_boxes | 6Ã—6 | 2 | ~20 moves |\n",
        "| complex | 10Ã—10 | 2 | ~18 moves |\n",
        "\n",
        "### References\n",
        "- [Debunking SFT Generalization](https://arxiv.org/pdf/2510.00237)\n",
        "- [LLMs + LangGraph for Sokoban](https://blog.gopenai.com/using-llms-and-langgraph-to-tackle-sokoban-puzzles-5f50b43b9515)\n",
        "- [HuggingFace Dataset](https://huggingface.co/datasets/Xiaofeng77/sokoban)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
