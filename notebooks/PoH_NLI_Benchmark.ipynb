{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† PoH vs BERT: Natural Language Inference Benchmark\n",
        "**Eran Ben-Artzy ‚Äî October 2025**\n",
        "\n",
        "This notebook benchmarks **BERT** against **PoH Transformer** on Natural Language Inference (NLI) task.\n",
        "\n",
        "---\n",
        "\n",
        "## Task: Natural Language Inference\n",
        "\n",
        "Given a **premise** and **hypothesis**, classify their relationship:\n",
        "- ‚úÖ **Entailment**: hypothesis follows from premise\n",
        "- ‚öñÔ∏è **Neutral**: hypothesis could be true\n",
        "- ‚ùå **Contradiction**: hypothesis contradicts premise\n",
        "\n",
        "**Example:**\n",
        "- Premise: \"A man is playing guitar\"\n",
        "- Hypothesis: \"A musician is performing\" ‚Üí **Entailment**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio pandas matplotlib seaborn pyyaml tqdm --quiet\n",
        "\n",
        "# Clone repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n",
        "\n",
        "# Optional: Update to latest\n",
        "# !git pull\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Quick Benchmark (100 steps, ~3 minutes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!PYTHONPATH=$PWD python experiments/quick_nli_test.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Full Benchmark (10K steps, ~30 minutes) - Optional\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to run full benchmark\n",
        "# !PYTHONPATH=$PWD python experiments/fair_ab_nli.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "This benchmark compares:\n",
        "\n",
        "### Models\n",
        "- **BERT-Base**: Standard transformer encoder (12 layers, 768 dim, 12 heads)\n",
        "- **PoH**: Same architecture + adaptive head routing + iterative refinement\n",
        "\n",
        "### Key Features\n",
        "- ‚úÖ Fair comparison (matched parameters & hyperparameters)\n",
        "- ‚úÖ Synthetic NLI data (no external dependencies)  \n",
        "- ‚úÖ 3-way classification (entailment/neutral/contradiction)\n",
        "- ‚úÖ Automatic result logging\n",
        "\n",
        "### Expected Outcome\n",
        "PoH should achieve **higher accuracy** than BERT baseline by leveraging:\n",
        "- Adaptive head routing (focus on relevant attention patterns)\n",
        "- Iterative refinement (multi-step reasoning)\n",
        "- Outer residuals (stable gradient flow)\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Eran Ben-Artzy  \n",
        "**License:** Apache 2.0  \n",
        "**Year:** 2025\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
