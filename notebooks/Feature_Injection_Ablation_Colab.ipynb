{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ Feature Injection Ablation Study\n",
        "\n",
        "Benchmark all **6 Feature Injection modes** on Sudoku-Extreme dataset.\n",
        "\n",
        "## Experiment 1: Injection Mode Comparison\n",
        "| Mode | Description |\n",
        "|------|-------------|\n",
        "| `none` | Routing-only (baseline) |\n",
        "| `broadcast` | Gated broadcast to all tokens |\n",
        "| `film` | FiLM modulation (Œ≥*x + Œ≤) |\n",
        "| `depth_token` | Prepend depth token |\n",
        "| `cross_attn` | Cross-attention to memory bank |\n",
        "| `alpha_gated` | Alpha-modulated broadcast |\n",
        "\n",
        "## Experiment 2: Alpha Aggregation Deep Dive\n",
        "| Aggregation | Formula |\n",
        "|-------------|--------|\n",
        "| `mean` | Average routing weight |\n",
        "| `max` | Maximum routing weight |\n",
        "| `entropy` | 1 - H(Œ±)/H_max (confident ‚Üí stronger) |\n",
        "\n",
        "## Configuration (Paper-Aligned)\n",
        "- **Dataset**: 9k Sudoku-Extreme puzzles\n",
        "- **Epochs**: 200 per experiment\n",
        "- **Batch size**: 768 (A100/H100)\n",
        "- **Warmup**: 2,000 steps\n",
        "- **H/L cycles**: 2/6\n",
        "- **Logging**: Weights & Biases\n",
        "- **GPU**: A100/H100 required (768 batch size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone PoT repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git /content/PoT 2>/dev/null || (cd /content/PoT && git pull)\n",
        "%cd /content/PoT\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q tqdm numpy huggingface_hub wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to Weights & Biases\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.data import download_sudoku_dataset\n",
        "\n",
        "# Download full 9k puzzles with 100 augmentations each (900k total samples)\n",
        "download_sudoku_dataset(\n",
        "    output_dir='data/sudoku-extreme-9k',\n",
        "    subsample_size=9000,\n",
        "    num_aug=100,  # 100 augmentations per puzzle\n",
        ")\n",
        "print(\"‚úì Dataset ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training Infrastructure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.data import SudokuDataset\n",
        "from src.pot.models import HybridPoHHRMSolver\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps, min_lr_ratio=0.1):\n",
        "    \"\"\"Cosine learning rate schedule with warmup.\"\"\"\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return step / max(1, warmup_steps)\n",
        "        progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
        "        return min_lr_ratio + (1 - min_lr_ratio) * 0.5 * (1 + math.cos(math.pi * progress))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, device):\n",
        "    \"\"\"Evaluate model on validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_cells = 0\n",
        "    total_cells = 0\n",
        "    correct_grids = 0\n",
        "    total_grids = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = batch['input'].to(device)\n",
        "            targets = batch['label'].to(device)\n",
        "            puzzle_ids = batch['puzzle_id'].to(device)\n",
        "            \n",
        "            logits, _, _, _ = model(inputs, puzzle_ids)\n",
        "            mask = (inputs == 0)\n",
        "            \n",
        "            if mask.any():\n",
        "                loss = F.cross_entropy(logits[mask], targets[mask])\n",
        "                total_loss += loss.item()\n",
        "            \n",
        "            preds = logits.argmax(dim=-1)\n",
        "            correct_cells += ((preds == targets) & mask).sum().item()\n",
        "            total_cells += mask.sum().item()\n",
        "            \n",
        "            grid_correct = ((preds == targets) | ~mask).all(dim=1)\n",
        "            correct_grids += grid_correct.sum().item()\n",
        "            total_grids += inputs.size(0)\n",
        "    \n",
        "    model.train()\n",
        "    return {\n",
        "        'loss': total_loss / len(val_loader),\n",
        "        'cell_acc': 100 * correct_cells / max(1, total_cells),\n",
        "        'grid_acc': 100 * correct_grids / max(1, total_grids),\n",
        "    }\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    injection_mode='none',\n",
        "    injection_kwargs=None,\n",
        "    epochs=200,\n",
        "    batch_size=768,\n",
        "    lr=3e-4,\n",
        "    warmup_steps=2000,\n",
        "    d_model=512,\n",
        "    n_heads=8,\n",
        "    H_cycles=2,\n",
        "    L_cycles=6,\n",
        "    H_layers=2,\n",
        "    L_layers=2,\n",
        "    halt_max_steps=4,\n",
        "    use_wandb=True,\n",
        "    run_name=None,\n",
        "    project='feature-injection-ablation',\n",
        "):\n",
        "    \"\"\"Train HybridPoHHRMSolver with specified injection mode.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Generate run name\n",
        "    if run_name is None:\n",
        "        timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "        if injection_kwargs:\n",
        "            extra = '-'.join(f\"{k}={v}\" for k, v in injection_kwargs.items())\n",
        "            run_name = f\"{injection_mode}-{extra}-{timestamp}\"\n",
        "        else:\n",
        "            run_name = f\"{injection_mode}-{timestamp}\"\n",
        "    \n",
        "    # Initialize W&B\n",
        "    if use_wandb:\n",
        "        wandb.init(\n",
        "            project=project,\n",
        "            name=run_name,\n",
        "            config={\n",
        "                'injection_mode': injection_mode,\n",
        "                'injection_kwargs': injection_kwargs,\n",
        "                'epochs': epochs,\n",
        "                'batch_size': batch_size,\n",
        "                'lr': lr,\n",
        "                'd_model': d_model,\n",
        "                'n_heads': n_heads,\n",
        "                'H_cycles': H_cycles,\n",
        "                'L_cycles': L_cycles,\n",
        "                'H_layers': H_layers,\n",
        "                'L_layers': L_layers,\n",
        "                'halt_max_steps': halt_max_steps,\n",
        "            },\n",
        "            reinit=True,\n",
        "        )\n",
        "    \n",
        "    # Load datasets\n",
        "    train_dataset = SudokuDataset('data/sudoku-extreme-9k/train.pt', augment=True)\n",
        "    val_dataset = SudokuDataset('data/sudoku-extreme-9k/val.pt', augment=False)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    print(f\"Train: {len(train_dataset)} samples, Val: {len(val_dataset)} samples\")\n",
        "    \n",
        "    # Create model\n",
        "    model = HybridPoHHRMSolver(\n",
        "        vocab_size=10,\n",
        "        d_model=d_model,\n",
        "        n_heads=n_heads,\n",
        "        H_layers=H_layers,\n",
        "        L_layers=L_layers,\n",
        "        d_ff=d_model * 4,\n",
        "        H_cycles=H_cycles,\n",
        "        L_cycles=L_cycles,\n",
        "        halt_max_steps=halt_max_steps,\n",
        "        injection_mode=injection_mode,\n",
        "        injection_kwargs=injection_kwargs,\n",
        "    ).to(device)\n",
        "    \n",
        "    n_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Model parameters: {n_params:,} ({n_params/1e6:.2f}M)\")\n",
        "    print(f\"Injection mode: {injection_mode}\")\n",
        "    if injection_kwargs:\n",
        "        print(f\"Injection kwargs: {injection_kwargs}\")\n",
        "    \n",
        "    # Optimizer and scheduler\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "    total_steps = epochs * len(train_loader)\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "    \n",
        "    # Training loop\n",
        "    best_grid_acc = 0\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_cells = 0\n",
        "        epoch_total = 0\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "        for batch in pbar:\n",
        "            inputs = batch['input'].to(device)\n",
        "            targets = batch['label'].to(device)\n",
        "            puzzle_ids = batch['puzzle_id'].to(device)\n",
        "            \n",
        "            logits, _, _, _ = model(inputs, puzzle_ids)\n",
        "            mask = (inputs == 0)\n",
        "            \n",
        "            if not mask.any():\n",
        "                continue\n",
        "            \n",
        "            loss = F.cross_entropy(logits[mask], targets[mask])\n",
        "            \n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                continue\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                preds = logits.argmax(dim=-1)\n",
        "                correct = ((preds == targets) & mask).sum().item()\n",
        "                epoch_cells += correct\n",
        "                epoch_total += mask.sum().item()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            cell_acc = 100 * epoch_cells / max(1, epoch_total)\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.3f}', 'cell': f'{cell_acc:.1f}%'})\n",
        "        \n",
        "        # Evaluate\n",
        "        val_metrics = evaluate(model, val_loader, device)\n",
        "        \n",
        "        # Log to W&B\n",
        "        if use_wandb:\n",
        "            wandb.log({\n",
        "                'epoch': epoch,\n",
        "                'train/loss': epoch_loss / len(train_loader),\n",
        "                'train/cell_acc': 100 * epoch_cells / max(1, epoch_total),\n",
        "                'val/loss': val_metrics['loss'],\n",
        "                'val/cell_acc': val_metrics['cell_acc'],\n",
        "                'val/grid_acc': val_metrics['grid_acc'],\n",
        "                'lr': scheduler.get_last_lr()[0],\n",
        "            })\n",
        "        \n",
        "        # Print progress every 10 epochs\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}: val_cell={val_metrics['cell_acc']:.2f}%, val_grid={val_metrics['grid_acc']:.2f}%\")\n",
        "        \n",
        "        # Save best model\n",
        "        if val_metrics['grid_acc'] > best_grid_acc:\n",
        "            best_grid_acc = val_metrics['grid_acc']\n",
        "            if use_wandb:\n",
        "                torch.save(model.state_dict(), f'/content/{run_name}_best.pt')\n",
        "                wandb.save(f'/content/{run_name}_best.pt')\n",
        "    \n",
        "    if use_wandb:\n",
        "        wandb.log({'best_grid_acc': best_grid_acc})\n",
        "        wandb.finish()\n",
        "    \n",
        "    return {\n",
        "        'injection_mode': injection_mode,\n",
        "        'injection_kwargs': injection_kwargs,\n",
        "        'best_grid_acc': best_grid_acc,\n",
        "        'final_cell_acc': val_metrics['cell_acc'],\n",
        "        'final_grid_acc': val_metrics['grid_acc'],\n",
        "    }\n",
        "\n",
        "print(\"‚úì Training infrastructure ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Experiment 1: Injection Mode Comparison\n",
        "\n",
        "Compare all 6 injection modes with identical hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Injection modes to compare\n",
        "INJECTION_MODES = [\n",
        "    ('none', None),                    # Baseline: routing only\n",
        "    ('broadcast', None),               # Gated broadcast\n",
        "    ('film', None),                    # FiLM modulation\n",
        "    ('depth_token', None),             # Depth token\n",
        "    ('cross_attn', {'memory_size': 16, 'n_heads': 4}),  # Cross-attention\n",
        "    ('alpha_gated', {'alpha_aggregation': 'mean'}),     # Alpha-gated (mean)\n",
        "]\n",
        "\n",
        "print(f\"Will run {len(INJECTION_MODES)} experiments:\")\n",
        "for mode, kwargs in INJECTION_MODES:\n",
        "    print(f\"  - {mode}: {kwargs if kwargs else 'default'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all injection mode experiments\n",
        "results_exp1 = []\n",
        "\n",
        "for injection_mode, injection_kwargs in INJECTION_MODES:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: {injection_mode}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    result = train_model(\n",
        "        injection_mode=injection_mode,\n",
        "        injection_kwargs=injection_kwargs,\n",
        "        epochs=200,\n",
        "        batch_size=768,\n",
        "        lr=3e-4,\n",
        "        warmup_steps=2000,\n",
        "        d_model=512,\n",
        "        n_heads=8,\n",
        "        H_cycles=2,\n",
        "        L_cycles=6,\n",
        "        halt_max_steps=4,\n",
        "        use_wandb=True,\n",
        "        project='feature-injection-ablation',\n",
        "    )\n",
        "    results_exp1.append(result)\n",
        "    print(f\"\\n‚úì {injection_mode}: grid_acc={result['best_grid_acc']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display Experiment 1 Results\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame(results_exp1)\n",
        "df1 = df1.sort_values('best_grid_acc', ascending=False)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPERIMENT 1: Injection Mode Comparison\")\n",
        "print(\"=\"*60)\n",
        "print(df1[['injection_mode', 'best_grid_acc', 'final_cell_acc']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment 2: Alpha Aggregation Deep Dive\n",
        "\n",
        "Compare different alpha aggregation strategies for `alpha_gated` mode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alpha aggregation modes to compare\n",
        "ALPHA_AGGREGATIONS = [\n",
        "    {'alpha_aggregation': 'mean', 'use_learned_gate': True},   # Mean + learned gate\n",
        "    {'alpha_aggregation': 'max', 'use_learned_gate': True},    # Max + learned gate\n",
        "    {'alpha_aggregation': 'entropy', 'use_learned_gate': True}, # Entropy + learned gate\n",
        "    {'alpha_aggregation': 'mean', 'use_learned_gate': False},  # Mean only (no learned gate)\n",
        "    {'alpha_aggregation': 'entropy', 'use_learned_gate': False}, # Entropy only (no learned gate)\n",
        "]\n",
        "\n",
        "print(f\"Will run {len(ALPHA_AGGREGATIONS)} alpha-gated experiments:\")\n",
        "for kwargs in ALPHA_AGGREGATIONS:\n",
        "    print(f\"  - {kwargs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all alpha aggregation experiments\n",
        "results_exp2 = []\n",
        "\n",
        "for injection_kwargs in ALPHA_AGGREGATIONS:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running alpha_gated with: {injection_kwargs}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    result = train_model(\n",
        "        injection_mode='alpha_gated',\n",
        "        injection_kwargs=injection_kwargs,\n",
        "        epochs=200,\n",
        "        batch_size=768,\n",
        "        lr=3e-4,\n",
        "        warmup_steps=2000,\n",
        "        d_model=512,\n",
        "        n_heads=8,\n",
        "        H_cycles=2,\n",
        "        L_cycles=6,\n",
        "        halt_max_steps=4,\n",
        "        use_wandb=True,\n",
        "        project='feature-injection-ablation',\n",
        "    )\n",
        "    results_exp2.append(result)\n",
        "    print(f\"\\n‚úì {injection_kwargs}: grid_acc={result['best_grid_acc']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display Experiment 2 Results\n",
        "df2 = pd.DataFrame(results_exp2)\n",
        "df2 = df2.sort_values('best_grid_acc', ascending=False)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPERIMENT 2: Alpha Aggregation Comparison\")\n",
        "print(\"=\"*60)\n",
        "print(df2[['injection_kwargs', 'best_grid_acc', 'final_cell_acc']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary & Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FEATURE INJECTION ABLATION STUDY - FINAL RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nüìä EXPERIMENT 1: Injection Mode Comparison\")\n",
        "print(\"-\"*50)\n",
        "for _, row in df1.iterrows():\n",
        "    print(f\"  {row['injection_mode']:15} | Grid: {row['best_grid_acc']:5.2f}% | Cell: {row['final_cell_acc']:5.2f}%\")\n",
        "\n",
        "print(\"\\nüìä EXPERIMENT 2: Alpha Aggregation Comparison\")\n",
        "print(\"-\"*50)\n",
        "for _, row in df2.iterrows():\n",
        "    kwargs = row['injection_kwargs']\n",
        "    agg = kwargs.get('alpha_aggregation', 'mean')\n",
        "    gate = 'gate' if kwargs.get('use_learned_gate', True) else 'no-gate'\n",
        "    print(f\"  {agg:8} + {gate:7} | Grid: {row['best_grid_acc']:5.2f}% | Cell: {row['final_cell_acc']:5.2f}%\")\n",
        "\n",
        "print(\"\\nüèÜ BEST OVERALL:\")\n",
        "all_results = results_exp1 + results_exp2\n",
        "best = max(all_results, key=lambda x: x['best_grid_acc'])\n",
        "print(f\"   Mode: {best['injection_mode']}\")\n",
        "print(f\"   Kwargs: {best['injection_kwargs']}\")\n",
        "print(f\"   Grid Accuracy: {best['best_grid_acc']:.2f}%\")\n",
        "\n",
        "print(\"\\n‚úì All experiments complete! Check W&B for detailed charts.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Quick Single Experiment (Optional)\n",
        "\n",
        "Run a single experiment with custom settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick single experiment (modify as needed)\n",
        "# result = train_model(\n",
        "#     injection_mode='alpha_gated',\n",
        "#     injection_kwargs={'alpha_aggregation': 'entropy', 'use_learned_gate': True},\n",
        "#     epochs=50,  # Quick test\n",
        "#     batch_size=128,\n",
        "#     use_wandb=True,\n",
        "#     run_name='alpha_gated_entropy_quick_test',\n",
        "# )\n",
        "# print(f\"Result: {result}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
