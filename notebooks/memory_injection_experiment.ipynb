{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Injection Experiment\n",
    "\n",
    "This notebook compares three injection modes to evaluate whether preserving\n",
    "injection memory across ACT steps improves Sudoku solving accuracy:\n",
    "\n",
    "1. **Baseline (`broadcast`)** — No memory, gated broadcast of controller state\n",
    "2. **Cross-Attention with Memory (`cross_attn`)** — Memory bank of past controller states, tokens cross-attend\n",
    "3. **Broadcast with Memory (`broadcast_memory`)** — Memory bank + learned summary + gated broadcast\n",
    "\n",
    "All runs share the same hyperparameters (d_model=512, H_cycles=2, L_cycles=6, halt_max_steps=4).\n",
    "\n",
    "**Key change:** `injection_memory` is now preserved across ACT steps via `ACTCarry`,\n",
    "so modes 2 and 3 can accumulate reasoning context over multiple outer iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup: clone repo and install deps\n",
    "!git clone https://github.com/Eran-BA/PoT.git\n",
    "%cd PoT\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q tqdm numpy huggingface_hub wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Hyperparameters\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| d_model | 512 |\n",
    "| d_ff | 2048 |\n",
    "| n_heads | 8 |\n",
    "| H_cycles | 2 |\n",
    "| L_cycles | 6 |\n",
    "| H_layers | 2 |\n",
    "| L_layers | 2 |\n",
    "| halt_max_steps | 4 |\n",
    "| controller | transformer |\n",
    "| d_ctrl | 256 |\n",
    "| epochs | 500 |\n",
    "| batch_size | 512 |\n",
    "| lr | 3e-4 |\n",
    "| warmup_steps | 2000 |\n",
    "| dropout | 0.039 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1: Baseline Broadcast (no memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!python experiments/sudoku_poh_benchmark.py \\\n",
    "    --d-model 512 \\\n",
    "    --d-ff 2048 \\\n",
    "    --model hybrid \\\n",
    "    --controller transformer \\\n",
    "    --d-ctrl 256 \\\n",
    "    --max-depth 32 \\\n",
    "    --injection-mode broadcast \\\n",
    "    --epochs 500 \\\n",
    "    --batch-size 512 \\\n",
    "    --lr 3e-4 \\\n",
    "    --warmup-steps 2000 \\\n",
    "    --n-heads 8 \\\n",
    "    --H-cycles 2 \\\n",
    "    --L-cycles 6 \\\n",
    "    --H-layers 2 \\\n",
    "    --L-layers 2 \\\n",
    "    --hrm-grad-style \\\n",
    "    --halt-max-steps 4 \\\n",
    "    --eval-interval 25 \\\n",
    "    --dropout 0.039 \\\n",
    "    --wandb \\\n",
    "    --project memory-injection-experiment \\\n",
    "    --run-name baseline-broadcast \\\n",
    "    --download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 2: Cross-Attention with Memory Preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!python experiments/sudoku_poh_benchmark.py \\\n",
    "    --d-model 512 \\\n",
    "    --d-ff 2048 \\\n",
    "    --model hybrid \\\n",
    "    --controller transformer \\\n",
    "    --d-ctrl 256 \\\n",
    "    --max-depth 32 \\\n",
    "    --injection-mode cross_attn \\\n",
    "    --injection-memory-size 16 \\\n",
    "    --injection-n-heads 4 \\\n",
    "    --epochs 500 \\\n",
    "    --batch-size 512 \\\n",
    "    --lr 3e-4 \\\n",
    "    --warmup-steps 2000 \\\n",
    "    --n-heads 8 \\\n",
    "    --H-cycles 2 \\\n",
    "    --L-cycles 6 \\\n",
    "    --H-layers 2 \\\n",
    "    --L-layers 2 \\\n",
    "    --hrm-grad-style \\\n",
    "    --halt-max-steps 4 \\\n",
    "    --eval-interval 25 \\\n",
    "    --dropout 0.039 \\\n",
    "    --wandb \\\n",
    "    --project memory-injection-experiment \\\n",
    "    --run-name cross-attn-memory \\\n",
    "    --download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 3: Broadcast with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!python experiments/sudoku_poh_benchmark.py \\\n",
    "    --d-model 512 \\\n",
    "    --d-ff 2048 \\\n",
    "    --model hybrid \\\n",
    "    --controller transformer \\\n",
    "    --d-ctrl 256 \\\n",
    "    --max-depth 32 \\\n",
    "    --injection-mode broadcast_memory \\\n",
    "    --injection-memory-size 16 \\\n",
    "    --injection-n-heads 4 \\\n",
    "    --epochs 500 \\\n",
    "    --batch-size 512 \\\n",
    "    --lr 3e-4 \\\n",
    "    --warmup-steps 2000 \\\n",
    "    --n-heads 8 \\\n",
    "    --H-cycles 2 \\\n",
    "    --L-cycles 6 \\\n",
    "    --H-layers 2 \\\n",
    "    --L-layers 2 \\\n",
    "    --hrm-grad-style \\\n",
    "    --halt-max-steps 4 \\\n",
    "    --eval-interval 25 \\\n",
    "    --dropout 0.039 \\\n",
    "    --wandb \\\n",
    "    --project memory-injection-experiment \\\n",
    "    --run-name broadcast-memory \\\n",
    "    --download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Step Accuracy Analysis\n",
    "\n",
    "Load the best checkpoint from each run and evaluate with intermediate output\n",
    "collection to see how accuracy improves across ACT steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from src.pot.models.sudoku_solver import HybridPoHHRMSolver\n",
    "from src.data.sudoku_dataset import SudokuDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_per_step(model, dataloader, device, max_batches=50):\n",
    "    \"\"\"\n",
    "    Evaluate model and compute per-ACT-step accuracy.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with per_step_cell_acc and per_step_grid_acc lists.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize per-step counters\n",
    "    n_steps = model.halt_max_steps\n",
    "    step_correct_cells = [0] * n_steps\n",
    "    step_total_cells = [0] * n_steps\n",
    "    step_correct_grids = [0] * n_steps\n",
    "    step_total_grids = [0] * n_steps\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if batch_idx >= max_batches:\n",
    "                break\n",
    "            \n",
    "            inp, label, puzzle_ids = batch\n",
    "            inp = inp.to(device)\n",
    "            label = label.to(device)\n",
    "            puzzle_ids = puzzle_ids.to(device)\n",
    "            \n",
    "            # Get intermediate outputs\n",
    "            result = model.forward_with_intermediate(inp, puzzle_ids)\n",
    "            \n",
    "            for step_idx, step_logits in enumerate(result['intermediate_logits']):\n",
    "                preds = step_logits.argmax(dim=-1)\n",
    "                \n",
    "                # Cell accuracy\n",
    "                step_correct_cells[step_idx] += (preds == label).sum().item()\n",
    "                step_total_cells[step_idx] += label.numel()\n",
    "                \n",
    "                # Grid accuracy\n",
    "                grid_correct = (preds == label).all(dim=1)\n",
    "                step_correct_grids[step_idx] += grid_correct.sum().item()\n",
    "                step_total_grids[step_idx] += label.size(0)\n",
    "    \n",
    "    # Compute percentages\n",
    "    n_actual = len(result['intermediate_logits'])  # May be fewer if early halting\n",
    "    per_step_cell_acc = [\n",
    "        100.0 * step_correct_cells[i] / max(step_total_cells[i], 1)\n",
    "        for i in range(n_actual)\n",
    "    ]\n",
    "    per_step_grid_acc = [\n",
    "        100.0 * step_correct_grids[i] / max(step_total_grids[i], 1)\n",
    "        for i in range(n_actual)\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        'per_step_cell_acc': per_step_cell_acc,\n",
    "        'per_step_grid_acc': per_step_grid_acc,\n",
    "    }\n",
    "\n",
    "print('evaluate_per_step defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_model(checkpoint_path, injection_mode, device):\n",
    "    \"\"\"\n",
    "    Load a trained model from checkpoint.\n",
    "    \n",
    "    Uses the same hyperparameters as the experiment runs.\n",
    "    \"\"\"\n",
    "    # Build injection kwargs\n",
    "    injection_kwargs = None\n",
    "    if injection_mode in ('cross_attn', 'broadcast_memory'):\n",
    "        injection_kwargs = {\n",
    "            'memory_size': 16,\n",
    "            'n_heads': 4,\n",
    "        }\n",
    "    \n",
    "    model = HybridPoHHRMSolver(\n",
    "        d_model=512,\n",
    "        n_heads=8,\n",
    "        H_layers=2,\n",
    "        L_layers=2,\n",
    "        d_ff=2048,\n",
    "        dropout=0.039,\n",
    "        H_cycles=2,\n",
    "        L_cycles=6,\n",
    "        T=32,\n",
    "        num_puzzles=1,\n",
    "        hrm_grad_style=True,\n",
    "        halt_max_steps=4,\n",
    "        controller_type='transformer',\n",
    "        controller_kwargs={'d_ctrl': 256},\n",
    "        injection_mode=injection_mode,\n",
    "        injection_kwargs=injection_kwargs,\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    epoch = checkpoint.get('epoch', '?')\n",
    "    grid_acc = checkpoint.get('test_grid_acc', '?')\n",
    "    print(f'Loaded {injection_mode} model from epoch {epoch}, grid_acc={grid_acc}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('load_model defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load validation dataset\n",
    "val_dataset = SudokuDataset(split='test', download=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "print(f'Validation set: {len(val_dataset)} puzzles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ---- Update these paths to your best checkpoints ----\n",
    "CHECKPOINTS = {\n",
    "    'broadcast':        'outputs/baseline-broadcast/best_model.pt',\n",
    "    'cross_attn':       'outputs/cross-attn-memory/best_model.pt',\n",
    "    'broadcast_memory': 'outputs/broadcast-memory/best_model.pt',\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for mode, ckpt_path in CHECKPOINTS.items():\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f'Skipping {mode}: checkpoint not found at {ckpt_path}')\n",
    "        continue\n",
    "    \n",
    "    model = load_model(ckpt_path, mode, device)\n",
    "    metrics = evaluate_per_step(model, val_loader, device)\n",
    "    results[mode] = metrics\n",
    "    \n",
    "    print(f'\\n{mode}:')\n",
    "    for step_idx, (cell, grid) in enumerate(zip(\n",
    "        metrics['per_step_cell_acc'], metrics['per_step_grid_acc']\n",
    "    )):\n",
    "        print(f'  Step {step_idx+1}: cell={cell:.2f}%, grid={grid:.2f}%')\n",
    "    \n",
    "    del model  # Free GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print('\\nDone evaluating all models.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Per-Step Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = {\n",
    "    'broadcast': '#1f77b4',\n",
    "    'cross_attn': '#ff7f0e',\n",
    "    'broadcast_memory': '#2ca02c',\n",
    "}\n",
    "labels = {\n",
    "    'broadcast': 'Broadcast (baseline)',\n",
    "    'cross_attn': 'Cross-Attn + Memory',\n",
    "    'broadcast_memory': 'Broadcast + Memory',\n",
    "}\n",
    "\n",
    "for mode, metrics in results.items():\n",
    "    steps = list(range(1, len(metrics['per_step_cell_acc']) + 1))\n",
    "    \n",
    "    ax1.plot(steps, metrics['per_step_cell_acc'],\n",
    "             marker='o', color=colors[mode], label=labels[mode], linewidth=2)\n",
    "    ax2.plot(steps, metrics['per_step_grid_acc'],\n",
    "             marker='o', color=colors[mode], label=labels[mode], linewidth=2)\n",
    "\n",
    "ax1.set_xlabel('ACT Step')\n",
    "ax1.set_ylabel('Cell Accuracy (%)')\n",
    "ax1.set_title('Cell Accuracy per ACT Step')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticks(range(1, 5))\n",
    "\n",
    "ax2.set_xlabel('ACT Step')\n",
    "ax2.set_ylabel('Grid Accuracy (%)')\n",
    "ax2.set_title('Grid Accuracy per ACT Step')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticks(range(1, 5))\n",
    "\n",
    "plt.suptitle('Memory Injection Experiment: Per-Step Accuracy', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('memory_injection_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Plot saved to memory_injection_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(f'{\"Mode\":<25} {\"Final Cell Acc (%)\":<20} {\"Final Grid Acc (%)\":<20} {\"Step 1 -> Final Gain\"}')\n",
    "print('-' * 85)\n",
    "\n",
    "for mode, metrics in results.items():\n",
    "    cell_accs = metrics['per_step_cell_acc']\n",
    "    grid_accs = metrics['per_step_grid_acc']\n",
    "    gain = grid_accs[-1] - grid_accs[0] if len(grid_accs) > 1 else 0\n",
    "    print(f'{labels.get(mode, mode):<25} {cell_accs[-1]:<20.2f} {grid_accs[-1]:<20.2f} {gain:+.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
