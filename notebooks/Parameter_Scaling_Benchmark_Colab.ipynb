{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameter Scaling Benchmark - PoH-HRM vs Baseline Transformer\n",
        "\n",
        "This notebook runs a parameter scaling experiment comparing:\n",
        "- **Baseline Transformer** (standard multi-head attention)\n",
        "- **PoH-HRM** (Pointer-over-Heads with Hierarchical Reasoning Module)\n",
        "\n",
        "We now focus on the two largest scales for clear differentiation:\n",
        "- **Large** (~30M params)\n",
        "- **XL** (~100M params)\n",
        "\n",
        "Additionally, an optional section allows testing a **HUGE (~500M)** model.\n",
        "\n",
        "Parameter parity is enforced: PoH-HRM is auto-adjusted to have equal or fewer parameters than the baseline (≤10% tolerance), favoring fewer when feasible.\n",
        "\n",
        "**Key Questions:**\n",
        "1. Does PoH-HRM maintain its advantage at large scales?\n",
        "2. How does advantage change from Large to XL (and optionally to HUGE)?\n",
        "3. Does performance saturate or continue improving?\n",
        "\n",
        "**Runtime:** ~1–2 hours on A100 GPU (Large + XL). HUGE is heavier; start with fewer epochs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git\n",
        "%cd PoT\n",
        "\n",
        "# Switch to scaling branch\n",
        "!git checkout scaling_parameter_size\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch transformers numpy matplotlib tqdm\n",
        "!pip install -q maze-dataset\n",
        "\n",
        "# Verify GPU\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    try:\n",
        "        import torch.backends.mps\n",
        "        print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
        "    except Exception as e:\n",
        "        print(\"MPS check failed\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Adjust these parameters as needed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Benchmark configuration\n",
        "MAZE_SIZE = 16        # Maze grid size (16x16)\n",
        "N_TRAIN = 1000        # Training samples per model\n",
        "N_TEST = 100          # Test samples\n",
        "EPOCHS = 50           # Training epochs per model\n",
        "R = 4                 # PoH refinement iterations\n",
        "T = 4                 # HRM outer loop period\n",
        "SEED = 42             # Random seed\n",
        "\n",
        "# For faster testing (recommended for first run):\n",
        "# MAZE_SIZE = 12\n",
        "# N_TRAIN = 500\n",
        "# N_TEST = 50\n",
        "# EPOCHS = 30\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Benchmark\n",
        "\n",
        "This will test the two largest model sizes (Large and XL) with parameter parity.\n",
        "\n",
        "**Progress:**\n",
        "1. Generate training/test data (once)\n",
        "2. For each size (Large → XL):\n",
        "   - Train Baseline Transformer\n",
        "   - Evaluate Baseline\n",
        "   - Train PoH-HRM (depth auto-adjusts for param parity)\n",
        "   - Evaluate PoH-HRM\n",
        "3. Save results\n",
        "\n",
        "**Note:** Large and XL may take 30–60 minutes each. Use fewer epochs for a quick run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Large and XL only (parity enforced inside the script)\n",
        "!python experiments/parameter_scaling_benchmark.py \\\n",
        "    --maze-size {MAZE_SIZE} \\\n",
        "    --train {N_TRAIN} \\\n",
        "    --test {N_TEST} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --R {R} \\\n",
        "    --T {T} \\\n",
        "    --seed {SEED} \\\n",
        "    --output experiments/results/parameter_scaling_colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load results\n",
        "with open(f'experiments/results/parameter_scaling_colab/scaling_results_maze{MAZE_SIZE}.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "results = data['results']\n",
        "config = data['config']\n",
        "\n",
        "# Extract data\n",
        "sizes = [r['size'] for r in results]\n",
        "baseline_params = [r['baseline_params'] / 1e6 for r in results]\n",
        "poh_params = [r['poh_params'] / 1e6 for r in results]\n",
        "\n",
        "baseline_acc = [r['baseline_acc'] for r in results]\n",
        "poh_acc = [r['poh_acc'] for r in results]\n",
        "\n",
        "baseline_opt = [r['baseline_opt'] for r in results]\n",
        "poh_opt = [r['poh_opt'] for r in results]\n",
        "\n",
        "poh_adv_acc = [r['poh_advantage_acc'] for r in results]\n",
        "poh_adv_opt = [r['poh_advantage_opt'] for r in results]\n",
        "\n",
        "# Create plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Accuracy vs Parameters\n",
        "ax = axes[0, 0]\n",
        "ax.plot(baseline_params, baseline_acc, 'o-', label='Baseline', linewidth=2, markersize=8)\n",
        "ax.plot(poh_params, poh_acc, 's-', label='PoH-HRM', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Parameters (M)', fontsize=12)\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax.set_title(f'Accuracy vs. Model Size\\\\n(Maze {config[\"maze_size\"]}×{config[\"maze_size\"]})', fontsize=13, fontweight='bold')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# Plot 2: Optimality vs Parameters\n",
        "ax = axes[0, 1]\n",
        "ax.plot(baseline_params, baseline_opt, 'o-', label='Baseline', linewidth=2, markersize=8)\n",
        "ax.plot(poh_params, poh_opt, 's-', label='PoH-HRM', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Parameters (M)', fontsize=12)\n",
        "ax.set_ylabel('Optimality (%)', fontsize=12)\n",
        "ax.set_title(f'Optimality vs. Model Size\\\\n(Maze {config[\"maze_size\"]}×{config[\"maze_size\"]})', fontsize=13, fontweight='bold')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xscale('log')\n",
        "\n",
        "# Plot 3: PoH Advantage in Accuracy\n",
        "ax = axes[1, 0]\n",
        "colors = ['green' if x > 0 else 'red' for x in poh_adv_acc]\n",
        "ax.bar(sizes, poh_adv_acc, color=colors, alpha=0.7)\n",
        "ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.set_xlabel('Model Size', fontsize=12)\n",
        "ax.set_ylabel('PoH Advantage (%)', fontsize=12)\n",
        "ax.set_title('PoH-HRM Accuracy Advantage\\\\n(PoH - Baseline)', fontsize=13, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 4: PoH Advantage in Optimality\n",
        "ax = axes[1, 1]\n",
        "colors = ['green' if x > 0 else 'red' for x in poh_adv_opt]\n",
        "ax.bar(sizes, poh_adv_opt, color=colors, alpha=0.7)\n",
        "ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.set_xlabel('Model Size', fontsize=12)\n",
        "ax.set_ylabel('PoH Advantage (%)', fontsize=12)\n",
        "ax.set_title('PoH-HRM Optimality Advantage\\\\n(PoH - Baseline)', fontsize=13, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'scaling_plot_maze{config[\"maze_size\"]}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\\\n✓ Plot saved to: scaling_plot_maze{config['maze_size']}.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*100)\n",
        "print(f\"PARAMETER SCALING RESULTS - Maze {config['maze_size']}×{config['maze_size']}\")\n",
        "print(\"=\"*100)\n",
        "print(f\"Training: {config['n_train']} samples, {config['epochs']} epochs\")\n",
        "print(f\"Testing: {config['n_test']} samples\")\n",
        "print(f\"PoH Config: R={config['R']}, T={config['T']}\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "print(f\"{'Size':<10} {'Params (M)':<20} {'Accuracy (%)':<25} {'Optimality (%)':<25}\")\n",
        "print(f\"{'':<10} {'Baseline / PoH':<20} {'Baseline / PoH / Δ':<25} {'Baseline / PoH / Δ':<25}\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "for r in results:\n",
        "    print(f\"{r['size']:<10} \"\n",
        "          f\"{r['baseline_params']/1e6:>5.1f} / {r['poh_params']/1e6:>5.1f}   \"\n",
        "          f\"{r['baseline_acc']:>5.1f} / {r['poh_acc']:>5.1f} / {r['poh_advantage_acc']:>+5.1f}   \"\n",
        "          f\"{r['baseline_opt']:>5.1f} / {r['poh_opt']:>5.1f} / {r['poh_advantage_opt']:>+5.1f}\")\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"\\\\nKey Findings:\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Calculate average advantage\n",
        "avg_adv_acc = np.mean([r['poh_advantage_acc'] for r in results])\n",
        "avg_adv_opt = np.mean([r['poh_advantage_opt'] for r in results])\n",
        "\n",
        "print(f\"Average PoH Advantage (Accuracy): {avg_adv_acc:+.2f}%\")\n",
        "print(f\"Average PoH Advantage (Optimality): {avg_adv_opt:+.2f}%\")\n",
        "print()\n",
        "\n",
        "# Find best size for PoH\n",
        "best_acc_idx = np.argmax([r['poh_acc'] for r in results])\n",
        "best_opt_idx = np.argmax([r['poh_opt'] for r in results])\n",
        "\n",
        "print(f\"Best PoH Accuracy: {results[best_acc_idx]['size']} \"\n",
        "      f\"({results[best_acc_idx]['poh_acc']:.1f}% @ {results[best_acc_idx]['poh_params']/1e6:.1f}M params)\")\n",
        "print(f\"Best PoH Optimality: {results[best_opt_idx]['size']} \"\n",
        "      f\"({results[best_opt_idx]['poh_opt']:.1f}% @ {results[best_opt_idx]['poh_params']/1e6:.1f}M params)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: HUGE (~500M) Benchmark\n",
        "\n",
        "Run a much larger model using `experiments/huge_500m_benchmark.py`.\n",
        "Parameter parity is enforced by reducing PoH depth to ≤10% overhead vs baseline.\n",
        "\n",
        "Notes:\n",
        "- Start with fewer epochs (e.g., 5–10)\n",
        "- Lower batch size if you hit OOM\n",
        "- Runtime is significantly higher than Large/XL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example HUGE run (adjust epochs/batch-size to your GPU)\n",
        "!python experiments/huge_500m_benchmark.py \\\n",
        "  --maze-size {MAZE_SIZE} \\\n",
        "  --train 2000 \\\n",
        "  --test 200 \\\n",
        "  --epochs 10 \\\n",
        "  --batch-size 8 \\\n",
        "  --R 4 --T 4 \\\n",
        "  --output experiments/results/huge_500m\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
