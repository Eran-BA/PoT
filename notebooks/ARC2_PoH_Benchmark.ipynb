{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  HybridPoHHRM ARC-2 Benchmark\n",
        "\n",
        "Train an **Abstract Reasoning AI** on the **ARC-AGI-2** dataset using **HybridPoHHRM** - combining HRM's two-timescale reasoning with PoT head routing.\n",
        "\n",
        "## Architecture\n",
        "- **z_H, z_L**: Persistent hidden states (HRM-style)\n",
        "- **L_level**: Fast reasoning (inner loop, 8 cycles)\n",
        "- **H_level**: Slow reasoning (outer loop, 2 cycles)\n",
        "- **PoT head routing**: Dynamic attention head selection in both levels\n",
        "- **2D Positional Embeddings**: For spatial reasoning on 30x30 grids\n",
        "- **On-the-fly Augmentation**: Color permutation, dihedral transforms, translation\n",
        "\n",
        "## ARC-AGI-2 Dataset\n",
        "| Split | Puzzles | Description |\n",
        "|-------|---------|-------------|\n",
        "| Training | 1,000 | Public training tasks |\n",
        "| Evaluation | 120 | Public evaluation tasks |\n",
        "| Human Performance | 66% | Average human accuracy |\n",
        "\n",
        "## Hardware Requirements\n",
        "- **GPU**: H100/A100 recommended (40-80GB VRAM)\n",
        "- **Memory**: ARC uses 900 tokens (30x30) vs Sudoku's 81 (9x9)\n",
        "- **Runtime**: ~24-48 hours for full training (20K epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone PoT repository\n",
        "!git clone https://github.com/Eran-BA/PoT.git /content/PoT 2>/dev/null || (cd /content/PoT && git pull)\n",
        "%cd /content/PoT\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q tqdm numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Download ARC-AGI-2 Dataset\n",
        "\n",
        "Downloads from [arcprize/ARC-AGI-2](https://github.com/arcprize/ARC-AGI-2):\n",
        "- **Training**: ~1,000 puzzles with train examples\n",
        "- **Evaluation**: ~120 puzzles with test examples\n",
        "- **On-the-fly augmentation** during training (like Sudoku):\n",
        "  - Color permutation (1-9 shuffled, 0 fixed)\n",
        "  - Dihedral transforms (8 rotations/flips)\n",
        "  - Translational augmentation (random position in 30x30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and build ARC-2 dataset (minimal, uses on-the-fly augmentation like Sudoku)\n",
        "!python scripts/build_arc_dataset.py \\\n",
        "    --version arc-2 \\\n",
        "    --num-aug 0 \\\n",
        "    --output-dir data/arc-2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train HybridPoHHRM ARC Solver\n",
        "\n",
        "### Configuration (HRM-Aligned)\n",
        "```yaml\n",
        "# Model\n",
        "d_model: 512, n_heads: 8\n",
        "H_cycles: 2, L_cycles: 8  # Two-timescale reasoning\n",
        "H_layers: 2, L_layers: 2\n",
        "halt_max_steps: 4         # ACT outer steps\n",
        "\n",
        "# Training (HRM-aligned)\n",
        "lr: 1e-4, weight_decay: 1.0\n",
        "betas: (0.9, 0.95)        # Llama-style\n",
        "warmup_steps: 2000\n",
        "lr_min_ratio: 0.1         # Cosine decay floor\n",
        "batch_size: 32            # Smaller than Sudoku (larger seq_len)\n",
        "\n",
        "# On-the-fly Augmentation (like Sudoku)\n",
        "- Color permutation: shuffle colors 1-9, keep 0 fixed\n",
        "- Dihedral transforms: 8 rotations/flips\n",
        "- Translation: random position in 30x30 grid\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full training (H100/A100) - HRM-aligned configuration\n",
        "!python experiments/arc_poh_benchmark.py \\\n",
        "    --data-dir data/arc-2 \\\n",
        "    --model hybrid \\\n",
        "    --hrm-grad-style \\\n",
        "    --halt-max-steps 4 \\\n",
        "    --async-batch \\\n",
        "    --lr 1e-4 \\\n",
        "    --batch-size 32 \\\n",
        "    --weight-decay 1.0 \\\n",
        "    --puzzle-weight-decay 1.0 \\\n",
        "    --puzzle-lr-multiplier 1.0 \\\n",
        "    --puzzle-optimizer signsgd \\\n",
        "    --beta2 0.95 \\\n",
        "    --warmup-steps 2000 \\\n",
        "    --lr-min-ratio 0.1 \\\n",
        "    --dropout 0.0 \\\n",
        "    --epochs 20000 \\\n",
        "    --eval-interval 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Quick Test (~2-4 hours)\n",
        "\n",
        "For a quick sanity check on T4/V100, run with fewer epochs:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test (~2-4 hours on T4/V100)\n",
        "!python experiments/arc_poh_benchmark.py \\\n",
        "    --data-dir data/arc-2 \\\n",
        "    --model hybrid \\\n",
        "    --hrm-grad-style \\\n",
        "    --halt-max-steps 4 \\\n",
        "    --lr 1e-4 \\\n",
        "    --batch-size 16 \\\n",
        "    --weight-decay 1.0 \\\n",
        "    --puzzle-optimizer signsgd \\\n",
        "    --beta2 0.95 \\\n",
        "    --warmup-steps 500 \\\n",
        "    --epochs 2000 \\\n",
        "    --eval-interval 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from src.data.arc import ARCDataset\n",
        "from src.pot.models.arc_solver import HybridPoHARCSolver\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load test set (use same data dir as training)\n",
        "test_dataset = ARCDataset('data/arc-2', 'test', augment=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "print(f\"Test set: {len(test_dataset)} examples\")\n",
        "\n",
        "# Load best model (match training config!)\n",
        "model = HybridPoHARCSolver(\n",
        "    d_model=512, n_heads=8,\n",
        "    H_layers=2, L_layers=2, d_ff=2048,\n",
        "    dropout=0.0,\n",
        "    H_cycles=2, L_cycles=8, T=4,\n",
        "    hrm_grad_style=True,\n",
        "    halt_max_steps=4,\n",
        "    num_puzzles=1,\n",
        ").to(device)\n",
        "\n",
        "checkpoint = torch.load('experiments/results/arc_poh/hybrid_best.pt', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
        "print(f\"Val accuracy: {checkpoint['test_grid_acc']:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "@torch.no_grad()\n",
        "def evaluate_arc(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_cells = 0\n",
        "    total_cells = 0\n",
        "    correct_grids = 0\n",
        "    total_grids = 0\n",
        "    pad_id = 0\n",
        "    \n",
        "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "        inp = batch['input'].to(device)\n",
        "        label = batch['label'].to(device)\n",
        "        puzzle_ids = batch['puzzle_id'].to(device)\n",
        "        \n",
        "        logits = model(inp, puzzle_ids)[0]\n",
        "        \n",
        "        loss = F.cross_entropy(\n",
        "            logits.view(-1, model.vocab_size),\n",
        "            label.view(-1),\n",
        "            ignore_index=pad_id,\n",
        "        )\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        preds = logits.argmax(dim=-1)\n",
        "        mask = label != pad_id\n",
        "        correct_cells += ((preds == label) & mask).sum().item()\n",
        "        total_cells += mask.sum().item()\n",
        "        \n",
        "        grid_correct = ((preds == label) | ~mask).all(dim=1)\n",
        "        correct_grids += grid_correct.sum().item()\n",
        "        total_grids += inp.size(0)\n",
        "    \n",
        "    return {\n",
        "        'loss': total_loss / len(dataloader),\n",
        "        'cell_acc': 100 * correct_cells / max(1, total_cells),\n",
        "        'grid_acc': 100 * correct_grids / max(1, total_grids),\n",
        "    }\n",
        "\n",
        "print(\"\\nEvaluating on ARC-2 test set...\")\n",
        "test_metrics = evaluate_arc(model, test_loader, device)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"FINAL TEST RESULTS\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"  Loss: {test_metrics['loss']:.4f}\")\n",
        "print(f\"  Cell Accuracy: {test_metrics['cell_acc']:.2f}%\")\n",
        "print(f\"  Grid Accuracy: {test_metrics['grid_acc']:.2f}%\")\n",
        "print(f\"\\n  Human Performance: ~66%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "\n",
        "# ARC color palette\n",
        "ARC_COLORS = [\n",
        "    '#000000',  # 0: black\n",
        "    '#0074D9',  # 1: blue\n",
        "    '#FF4136',  # 2: red\n",
        "    '#2ECC40',  # 3: green\n",
        "    '#FFDC00',  # 4: yellow\n",
        "    '#AAAAAA',  # 5: grey\n",
        "    '#F012BE',  # 6: magenta\n",
        "    '#FF851B',  # 7: orange\n",
        "    '#7FDBFF',  # 8: cyan\n",
        "    '#870C25',  # 9: brown\n",
        "]\n",
        "arc_cmap = mcolors.ListedColormap(ARC_COLORS)\n",
        "\n",
        "def plot_arc_grid(grid, title=\"\", ax=None):\n",
        "    \"\"\"Plot a single ARC grid with proper colors.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(4, 4))\n",
        "    \n",
        "    # Convert from token space (2-11) to color space (0-9)\n",
        "    grid_colors = np.clip(grid - 2, 0, 9)\n",
        "    mask = grid < 2\n",
        "    grid_colors[mask] = 0\n",
        "    \n",
        "    # Find content bounds\n",
        "    content = grid >= 2\n",
        "    if content.any():\n",
        "        rows = np.any(content, axis=1)\n",
        "        cols = np.any(content, axis=0)\n",
        "        r_min, r_max = np.where(rows)[0][[0, -1]]\n",
        "        c_min, c_max = np.where(cols)[0][[0, -1]]\n",
        "        grid_colors = grid_colors[r_min:r_max+1, c_min:c_max+1]\n",
        "    \n",
        "    ax.imshow(grid_colors, cmap=arc_cmap, vmin=0, vmax=9)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    for i in range(grid_colors.shape[0] + 1):\n",
        "        ax.axhline(i - 0.5, color='gray', linewidth=0.5)\n",
        "    for j in range(grid_colors.shape[1] + 1):\n",
        "        ax.axvline(j - 0.5, color='gray', linewidth=0.5)\n",
        "    return ax\n",
        "\n",
        "# Visualize some predictions\n",
        "model.eval()\n",
        "batch = next(iter(test_loader))\n",
        "inp = batch['input'][:4].to(device)\n",
        "label = batch['label'][:4].to(device)\n",
        "puzzle_ids = batch['puzzle_id'][:4].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model(inp, puzzle_ids)[0].argmax(dim=-1)\n",
        "\n",
        "fig, axes = plt.subplots(4, 3, figsize=(12, 16))\n",
        "for i in range(4):\n",
        "    inp_grid = inp[i].cpu().numpy().reshape(30, 30)\n",
        "    label_grid = label[i].cpu().numpy().reshape(30, 30)\n",
        "    pred_grid = preds[i].cpu().numpy().reshape(30, 30)\n",
        "    \n",
        "    mask = label_grid != 0\n",
        "    is_correct = ((pred_grid == label_grid) | ~mask).all()\n",
        "    \n",
        "    plot_arc_grid(inp_grid, \"Input\", axes[i, 0])\n",
        "    plot_arc_grid(label_grid, \"Ground Truth\", axes[i, 1])\n",
        "    plot_arc_grid(pred_grid, f\"Prediction {'âœ“' if is_correct else 'âœ—'}\", axes[i, 2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "- ARC-AGI-2 Repository: https://github.com/arcprize/ARC-AGI-2\n",
        "- ARC Prize: https://arcprize.org/\n",
        "- HRM Paper: https://arxiv.org/abs/2506.21734\n",
        "- HRM GitHub: https://github.com/sapientinc/HRM\n",
        "- PoT GitHub: https://github.com/Eran-BA/PoT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
