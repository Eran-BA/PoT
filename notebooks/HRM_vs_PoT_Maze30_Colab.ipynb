{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HRM vs PoT on Maze 30×30 Hard (Colab)\n",
        "\n",
        "This notebook benchmarks the original HRM (vendor/hrm) against our PoT-HRM on Maze 30×30 hard.\n",
        "\n",
        "- HRM repo: https://github.com/sapientinc/HRM/tree/main\n",
        "- HRM paper: https://arxiv.org/pdf/2506.21734\n",
        "- This repo: PoT (Pointer-over-Heads) with HRM integration\n",
        "\n",
        "Steps:\n",
        "1. Clone PoT and initialize submodules (includes HRM under `vendor/hrm`).\n",
        "2. Install requirements (CUDA + FlashAttention recommended; Colab A100 works).\n",
        "3. Build HRM Maze 30×30 dataset and run HRM training (reduced settings by default).\n",
        "4. Run PoT-HRM benchmark at 30×30 with HRM-style normalization.\n",
        "5. Summarize results and show paths to logs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "# Setup: clone repo and init submodules\n",
        "WORKDIR=/content/PoT\n",
        "if [ ! -d \"$WORKDIR\" ]; then\n",
        "  git clone https://github.com/Eran-BA/PoT.git $WORKDIR\n",
        "fi\n",
        "cd $WORKDIR\n",
        "# Initialize HRM submodule\n",
        "git submodule update --init --recursive\n",
        "\n",
        "# Optional: checkout scaling branch if needed\n",
        "# git checkout scaling_parameter_size\n",
        "# git pull\n",
        "\n",
        "python3 -V && pip -V\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "# Install deps\n",
        "pip install -q maze-dataset wandb\n",
        "# For HRM CUDA environment (FlashAttention etc.), Colab A100 includes CUDA; skip heavy installs here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "# Ensure repo and HRM submodule exist\n",
        "if [ ! -d \"/content/PoT\" ]; then\n",
        "  git clone https://github.com/Eran-BA/PoT.git /content/PoT\n",
        "fi\n",
        "cd /content/PoT\n",
        "git submodule update --init --recursive || true\n",
        "# Fallback: clone HRM directly if submodule didn't populate\n",
        "if [ ! -d \"/content/PoT/vendor/hrm\" ]; then\n",
        "  mkdir -p /content/PoT/vendor\n",
        "  git clone https://github.com/sapientinc/HRM /content/PoT/vendor/hrm\n",
        "fi\n",
        "\n",
        "# HRM: Build Maze 30x30 Hard dataset and run pretrain (reduced)\n",
        "# Require CUDA: enforce Colab GPU runtime (Runtime → Change runtime type → GPU)\n",
        "python - <<'PY'\n",
        "import torch, sys\n",
        "assert torch.cuda.is_available(), \"CUDA GPU not available. Enable GPU runtime and rerun.\"\n",
        "print(\"[HRM] CUDA available: \", torch.cuda.get_device_name(0))\n",
        "PY\n",
        "\n",
        "cd /content/PoT/vendor/hrm\n",
        "# Install HRM Python requirements\n",
        "pip install -q -r requirements.txt\n",
        "\n",
        "# Download and process HuggingFace dataset (sapientinc/maze-30x30-hard-1k)\n",
        "python dataset/build_maze_dataset.py --output-dir data/maze-30x30-hard-1k\n",
        "\n",
        "# Run HRM pretrain (reduced epochs for Colab)\n",
        "python pretrain.py data_path=data/maze-30x30-hard-1k epochs=500 eval_interval=50 lr=1e-4 puzzle_emb_lr=1e-4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -e\n",
        "# PoT: Run 30x30 benchmark (reduced) with HRM-style normalization\n",
        "cd /content/PoT\n",
        "python -u experiments/maze_scaling_benchmark.py \\\n",
        "  --maze-sizes 30 \\\n",
        "  --train 300 --test 60 \\\n",
        "  --R 4 --T 4 --heads 8 \\\n",
        "  --epochs 60 --seed 42 \\\n",
        "  --output experiments/results/colab_maze30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarize artifacts\n",
        "import os, json\n",
        "pot_dir = '/content/PoT/experiments/results/colab_maze30'\n",
        "hrm_dir = '/content/PoT/experiments/results/hrm_original_maze30'\n",
        "print('PoT logs:', os.listdir(pot_dir) if os.path.isdir(pot_dir) else 'not found')\n",
        "print('HRM logs:', os.listdir(hrm_dir) if os.path.isdir(hrm_dir) else 'not found')\n",
        "\n",
        "# If PoT wrote JSON summaries, show them (best-effort)\n",
        "for root, _, files in os.walk(pot_dir):\n",
        "    for f in files:\n",
        "        if f.endswith('.json'):\n",
        "            p = os.path.join(root, f)\n",
        "            try:\n",
        "                print('\\n', p)\n",
        "                print(json.dumps(json.load(open(p)), indent=2)[:1000])\n",
        "            except Exception as e:\n",
        "                print('Failed to read', p, e)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
